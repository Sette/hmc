{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc291da-2fb7-4e0d-95ba-3b822d9cfaab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T21:10:04.916381Z",
     "start_time": "2024-03-09T21:10:04.117703Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 19:13:09.585181: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-12 19:13:10.218752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= Tensorflow =========================\n",
      "GPUs availables: 1\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from hcml.model.arguments import  build\n",
    "from hcml.model.train import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d90f8a5-dd7e-4b0c-93d6-4e710c159fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477638fc-089b-4725-81f1-695364796db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set python level verbosity\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.DEBUG)\n",
    "\n",
    "# Set C++ Graph Execution level verbosity\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = str(tf.compat.v1.logging.DEBUG)\n",
    "\n",
    "base_path = \"/mnt/disks/data/fma/trains\"\n",
    "id = \"hierarchical_tworoots_dev\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a92da5-e8c4-4a52-87ea-fef1d0605416",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(base_path,id)\n",
    "tfrecords_path =os.path.join(train_path,'tfrecords')\n",
    "metadata_path = os.path.join(train_path,\"metadata.json\")\n",
    "labels_path = os.path.join(train_path,\"labels.json\")\n",
    "\n",
    "\n",
    "args = pd.Series({\n",
    "    \"batch_size\":64,\n",
    "    \"epochs\":10,\n",
    "    \"dropout\":0.5,\n",
    "    'patience':1,\n",
    "    'max_queue_size':64,\n",
    "    \"labels_path\": labels_path,\n",
    "    \"metadata_path\": metadata_path,\n",
    "    \"trainset_pattern\": os.path.join(tfrecords_path,'train'),\n",
    "    \"testset_pattern\": os.path.join(tfrecords_path,'test'),\n",
    "    \"valset_pattern\": os.path.join(tfrecords_path,'val')\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b033032f-4cb5-46bf-8ecc-3517ddaf6f51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hierarchical_tworoots_dev] Experiment started at 22:13:10\n",
      ".......................................\n",
      "batch_size                                                         64\n",
      "epochs                                                             10\n",
      "dropout                                                           0.5\n",
      "patience                                                            1\n",
      "max_queue_size                                                     64\n",
      "labels_path         /mnt/disks/data/fma/trains/hierarchical_tworoo...\n",
      "metadata_path       /mnt/disks/data/fma/trains/hierarchical_tworoo...\n",
      "trainset_pattern    /mnt/disks/data/fma/trains/hierarchical_tworoo...\n",
      "testset_pattern     /mnt/disks/data/fma/trains/hierarchical_tworoo...\n",
      "valset_pattern      /mnt/disks/data/fma/trains/hierarchical_tworoo...\n",
      "dtype: object\n",
      "batch_size                                                         64\n",
      "epochs                                                             10\n",
      "dropout                                                           0.5\n",
      "patience                                                            1\n",
      "max_queue_size                                                     64\n",
      "labels_path         /mnt/disks/data/fma/trains/hierarchical_tworoo...\n",
      "metadata_path       /mnt/disks/data/fma/trains/hierarchical_tworoo...\n",
      "trainset_pattern    /mnt/disks/data/fma/trains/hierarchical_tworoo...\n",
      "testset_pattern     /mnt/disks/data/fma/trains/hierarchical_tworoo...\n",
      "valset_pattern      /mnt/disks/data/fma/trains/hierarchical_tworoo...\n",
      "dtype: object\n",
      "{'sequence_size': 1280, 'max_depth': 4, 'levels_size': [2, 30, 16], 'val_path': '/mnt/disks/data/fma/trains/hierarchical_tworoots_dev/tfrecords/val', 'train_path': '/mnt/disks/data/fma/trains/hierarchical_tworoots_dev/tfrecords/train', 'test_path': '/mnt/disks/data/fma/trains/hierarchical_tworoots_dev/tfrecords/test', 'val_csv': '/mnt/disks/data/fma/trains/hierarchical_tworoots_dev/val.csv', 'train_csv': '/mnt/disks/data/fma/trains/hierarchical_tworoots_dev/train.csv', 'test_csv': '/mnt/disks/data/fma/trains/hierarchical_tworoots_dev/test.csv', 'trainset_count': 16791, 'validationset_count': 2007, 'testset_count': 4814}\n",
      "{'levels_size': {'level1': 2, 'level2': 30, 'level3': 16, 'level4': 3}, 'sequence_size': 1280, 'dropout': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/.cache/pypoetry/virtualenvs/hierarchical_multi-label_classification-GvVd3mwS-py3.11/lib/python3.11/site-packages/keras/src/layers/preprocessing/normalization.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-05-12 19:13:11.067297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9786 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'level5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.......................................\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(args)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m time_end \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mutcnow()\n\u001b[1;32m      7\u001b[0m time_elapsed \u001b[38;5;241m=\u001b[39m time_end \u001b[38;5;241m-\u001b[39m time_start\n",
      "File \u001b[0;32m~/git/hmc/hcml/model/train.py:37\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     30\u001b[0m params: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevels_size\u001b[39m\u001b[38;5;124m'\u001b[39m: levels_size,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence_size\u001b[39m\u001b[38;5;124m'\u001b[39m: metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m: args\u001b[38;5;241m.\u001b[39mdropout\n\u001b[1;32m     34\u001b[0m }\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(params)\n\u001b[0;32m---> 37\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(\n\u001b[1;32m     40\u001b[0m     model,\n\u001b[1;32m     41\u001b[0m     to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.png\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     show_trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m )\n",
      "File \u001b[0;32m~/git/hmc/hcml/model/model.py:69\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(levels_size, sequence_size, dropout)\u001b[0m\n\u001b[1;32m     67\u001b[0m fourth \u001b[38;5;241m=\u001b[39m build_classification(fourth_input, levels_size, dropout, input_shape\u001b[38;5;241m=\u001b[39mfcn_size\u001b[38;5;241m+\u001b[39mlevels_size[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel3\u001b[39m\u001b[38;5;124m'\u001b[39m], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     68\u001b[0m fifth_input \u001b[38;5;241m=\u001b[39m Concatenate(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)([OutputNormalization()(fourth), x])\n\u001b[0;32m---> 69\u001b[0m fifth \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfifth_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevels_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfcn_size\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mlevels_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevel4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevel5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel([music], [\n\u001b[1;32m     72\u001b[0m     first,\n\u001b[1;32m     73\u001b[0m     second,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     fifth,\n\u001b[1;32m     77\u001b[0m ], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEssentia\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#     _load_weights(model, weights_path)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\u001b[39;00m\n",
      "File \u001b[0;32m~/git/hmc/hcml/model/model.py:45\u001b[0m, in \u001b[0;36mbuild_classification\u001b[0;34m(x, levels_size, dropout, input_shape, name)\u001b[0m\n\u001b[1;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;28mint\u001b[39m(input_shape\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     44\u001b[0m x \u001b[38;5;241m=\u001b[39m Dropout(dropout)(x)\n\u001b[0;32m---> 45\u001b[0m x \u001b[38;5;241m=\u001b[39m Dense(\u001b[43mlevels_size\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_output\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyError\u001b[0m: 'level5'"
     ]
    }
   ],
   "source": [
    "\n",
    "time_start = dt.utcnow()\n",
    "print(\"[{}] Experiment started at {}\".format(id, time_start.strftime(\"%H:%M:%S\")))\n",
    "print(\".......................................\")\n",
    "print(args)\n",
    "run(args)\n",
    "time_end = dt.utcnow()\n",
    "time_elapsed = time_end - time_start\n",
    "print(\".......................................\")\n",
    "print(\"[{}] Experiment finished at {} / elapsed time {}s\".format(id, time_end.strftime(\"%H:%M:%S\"), time_elapsed.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb52c5-58a6-486d-a397-6ac32b772d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd467ee-e2ff-44a8-a871-3699ba909623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bffb8f-2e4a-4375-afff-83c52f10b6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
