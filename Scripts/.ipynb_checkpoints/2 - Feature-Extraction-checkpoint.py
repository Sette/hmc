#!/usr/bin/env python
# coding: utf-8

# In[1]:


import os
import csv
import json
import pandas as pd
import numpy as np
import tensorflow as tf
from math import ceil
from sklearn.utils import shuffle

from joblib import Parallel, delayed

import multiprocessing
from tqdm import tqdm

from essentia.standard import MonoLoader, TensorflowPredictEffnetDiscogs
from sklearn.model_selection import train_test_split


# #### Remove depreciated package and install from official repository of essentia

# In[2]:


# !pip uninstall essentia-tensorflow -y


# In[3]:


# !pip install -f https://essentia.upf.edu/python-wheels/ essentia-tensorflow --no-cache-dir


# ### Define paths

# In[4]:


args = pd.Series({
    "root_dir":"/mnt/disks/data/",
    "embeddings":"music_style",
    "train_id": "global_sample_test"
})


# In[5]:


train_id = "global_sample_test"


# In[13]:


sample_size = 0.1 ## 10% do conjunto de dados


# In[14]:


job_path = "/mnt/disks/data/fma/trains"


# In[15]:


train_path = os.path.join(job_path,train_id)


# In[16]:


base_path = os.path.join(args.root_dir,"fma")


# In[17]:


models_path = os.path.join(args.root_dir,"models")


# In[18]:


metadata_path = os.path.join(base_path,"fma_metadata")


# In[19]:


import os


def create_dir(path):
    # checking if the directory demo_folder2 
    # exist or not.
    if not os.path.isdir(path):

        # if the demo_folder2 directory is 
        # not present then create it.
        os.makedirs(path)
    return True


create_dir(train_path)

# In[20]:


if args.embeddings == "music_style":
    model_path = os.path.join(models_path,args.embeddings,"discogs-effnet-bs64-1.pb")


# #### Load dataset csv generated by "1 - Generate-Labels"

# In[21]:


def __load_json__(path):
    with open(path, 'r') as f:
        tmp = json.loads(f.read())

    return tmp

labels_path = os.path.join(metadata_path,"labels.json")

labels = __load_json__(labels_path)


df = pd.read_csv(os.path.join(metadata_path,"tracks_genres_id_full_clear.csv"))



# In[24]:


df = df.sample(frac=sample_size)


# In[25]:


model_path


# In[26]:


### Exemplo de extração de features
audio = MonoLoader(filename=df.iloc[1].file_path, sampleRate=16000)()
model = TensorflowPredictEffnetDiscogs(graphFilename=model_path,output="PartitionedCall:1")
activations = model(audio)


# In[27]:


activations.shape


# In[28]:


df.shape


# In[29]:


groups = df.groupby("first_genre_id_label")


# In[30]:


groups


# In[31]:



def __split_data__(group, percentage=0.1):
    if len(group) == 1:
        return group, group

    shuffled = shuffle(group.values)
    finish_test = int(ceil(len(group) * percentage))

    first = pd.DataFrame(shuffled[:finish_test], columns=group.columns)
    second = pd.DataFrame(shuffled[finish_test:], columns=group.columns)

    return first, second


# In[32]:


def __split_data_sample(groups):
    dataset_trainset_path = os.path.join(train_path,"trainset.csv")
    dataset_testset_path = os.path.join(train_path,"testset.csv")
    dataset_validationset_path = os.path.join(train_path,"validationset.csv")
    
    
    X_train,y_train,X_test,y_test,X_val,y_val = (list(),list(),list(),list(),list(),list())
    for code, group in groups:
        
        test, train_to_split  = __split_data__(group, 0.05) # 10%
        validation, train = __split_data__(train_to_split, 0.05) # %10
        #rint(test)
        
        X_train.append(train)
        X_test.append(test)
        X_val.append(validation)
        
    X_train = pd.concat(X_train, sort=False).sample(frac=1).reset_index(drop=True)
    X_train.to_csv(dataset_trainset_path, index=False, quoting=csv.QUOTE_ALL)
    print(dataset_trainset_path)
    
    X_test = pd.concat(X_test, sort=False).sample(frac=1).reset_index(drop=True)
    X_test.to_csv(dataset_testset_path, index=False, quoting=csv.QUOTE_ALL)
    print(dataset_testset_path)

    X_val = pd.concat(X_val, sort=False).sample(frac=1).reset_index(drop=True)
    X_val.to_csv(dataset_validationset_path, index=False, quoting=csv.QUOTE_ALL)
    print(dataset_validationset_path)
    
    return X_train,X_test,X_val


# In[33]:


X_train,X_test,X_validation = __split_data_sample(groups)


# In[36]:


X_validation.shape


# In[43]:


def extract_feature(file_path,model):
    ### Configuração do model para extrair a representação do aúdio
    # model = TensorflowPredictEffnetDiscogs(graphFilename=model_path)
    audio = MonoLoader(filename=file_path, sampleRate=16000)()
    activations = model(audio)
    return activations


# In[44]:


def _bytes_feature(value):
    """Returns a bytes_list from a string / byte."""
    if isinstance(value, type(tf.constant(0))): # if value ist tensor
        value = value.numpy() # get value of tensor
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

def _float_feature(value):
  """Returns a floast_list from a float / double."""
  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))

def _int64_feature(value):
  """Returns an int64_list from a bool / enum / int / uint."""
  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

def serialize_array(array):
  array = tf.io.serialize_tensor(array)
  return array


def parse_single_music(data,music,labels):
    path, cat1 = data
    
    label1 = np.array([cat1, len(labels['global'])], np.int64)
    
    
    
    #define the dictionary -- the structure -- of our single example
    data = {
        'emb' : _bytes_feature(serialize_array(music)),
        'label' : tf.train.Feature(int64_list=tf.train.Int64List(value=label1))
    }
    #create an Example, wrapping the single features
    out = tf.train.Example(features=tf.train.Features(feature=data))

    return out
# In[45]:



# In[54]:


def generate_tf_records(df,labels,model,filename="train"):
    
    tfrecords_path = os.path.join(train_path,"tfrecords",filename)
    
    create_dir(tfrecords_path)
    
    
    batch_size = 1024 * 1  # 10k records from each file batch
    count = 0
    total = ceil(len(df) / batch_size)
    
    for i in range(0, len(df), batch_size):
        batch_df = df[i:i+batch_size]
        
        tqdm.pandas()
        
        X = batch_df.file_path.progress_apply(lambda x: extract_feature(x,model))   
        
        print("Extraiu as features")
        
        
        tfrecords = [parse_single_music(data, x,labels) for data, x in zip(batch_df.values, X)]
        
        path = os.path.join(tfrecords_path,f"{str(count).zfill(10)}.tfrecord")

        #with tf.python_io.TFRecordWriter(path) as writer:
        with tf.io.TFRecordWriter(path) as writer:
            for tfrecord in tfrecords:
                writer.write(tfrecord.SerializeToString())

        print(f"{count} {len(tfrecords)} {path}")
        count += 1
        print(f"{count}/{total} batchs / {count * batch_size} processed")

    print(f"{count}/{total} batchs / {len(df)} processed")


# In[52]:


extract_feature(df.file_path.iloc[2],model)

dataset_names = ["train","teste","validation"]

datasets = [X_train,X_test,X_validation]


# In[ ]:

with Parallel(n_jobs=20, require='sharedmem') as para:
        print("Estamos usando paralelismo!!!")
        para(delayed(generate_tf_records)(dataset,labels,model,dataset_name) for (dataset_name,dataset) in zip(dataset_names,datasets))



# count_test = generate_tf_records(X_test,labels,model,filename="test")

# In[ ]:


# count_train = generate_tf_records(X_train,labels,model,filename="train")


# In[ ]:


# count_val = generate_tf_records(X_validation,labels,model,filename="val")


# In[ ]:


metadata = {
    "train_count":len(X_train),
    "test_count":len(X_test),
    "val_count":len(X_validation),
    "root_dir":args.root_dir,
    "embeddings":args.embeddings,
    "train_id": args.train_id
}


# In[ ]:


metadata_file_path = os.path.join(metadata_path,"metadata.json")


# In[ ]:


with open(metadata_file_path, 'w+') as f:
    f.write(json.dumps(metadata))


# In[ ]:



