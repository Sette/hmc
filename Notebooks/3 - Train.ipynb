{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9fb572-bb1b-435a-b329-5c295067093a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 15:20:57.175462: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 15:20:57.884736: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1500e7c-e11f-4e7e-9fb3-ad06f08ca7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = pd.Series({\n",
    "    \"root_dir\":\"/mnt/disks/data/\",\n",
    "    \"dataset_path\":\"/mnt/disks/data/fma/fma_large\",\n",
    "    \"embeddings\":\"music_style\",\n",
    "    \"train_id\": \"hierarchical_single\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de612e34-baf4-4d04-aa16-3a931e2ae188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_path = \"/mnt/disks/data/fma/trains\"\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "train_path = os.path.join(job_path,args.train_id)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "base_path = os.path.join(args.root_dir,\"fma\")\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "models_path = os.path.join(args.root_dir,\"models\")\n",
    "\n",
    "\n",
    "metadata_path_fma = os.path.join(base_path,\"fma_metadata\")\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "metadata_file = os.path.join(train_path,\"metadata.json\")\n",
    "\n",
    "\n",
    "labels_file = os.path.join(train_path,\"labels.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e024261-df17-48aa-8876-e8cea69e4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def __load_json__(path):\n",
    "    with open(path, 'r') as f:\n",
    "        tmp = json.loads(f.read())\n",
    "\n",
    "    return tmp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0541e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, tfrecords_path, epochs, batch_size):\n",
    "        self.tfrecords_path = tfrecords_path\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def list_files(self):\n",
    "        return [os.path.join(tfrecords_path,file_path) for file_path in os.listdir(tfrecords_path)]\n",
    "\n",
    "    def build(self):\n",
    "        files = self.list_files()\n",
    "\n",
    "        print(\"build_tf record: files_count: {} / batch_size: {} / epochs: {}\".format(len(files), self.batch_size, self.epochs))\n",
    "\n",
    "        ds = tf.data.TFRecordDataset(files, num_parallel_reads=multiprocessing.cpu_count())\n",
    "                      \n",
    "\n",
    "        return ds\n",
    "    \n",
    "   \n",
    "    @staticmethod\n",
    "    def __parse__(example):\n",
    "        parsed = tf.parse_single_example(example, features={\n",
    "            'emb' : tf.io.FixedLenFeature([], tf.string),\n",
    "            'track_id' : tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True)\n",
    "        })\n",
    "        \n",
    "        content = tf.io.parse_single_example(element, data)\n",
    "\n",
    "        label = tf.cast(content['track_id'], tf.int32)\n",
    "        label_hot = tf.one_hot(label1[0], label1[1])\n",
    "        \n",
    "        emb = content['emb']\n",
    "        #get our 'feature'\n",
    "        feature = tf.io.parse_tensor(emb, out_type=tf.float32)\n",
    "\n",
    "        inp = {'emb': feature}\n",
    "        out = {'global_output': label_hot}\n",
    "\n",
    "        return inp, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0369afd-5070-44a7-b14c-d5a58c762969",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n",
    "        value = value.numpy() # get value of tensor\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a floast_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_array(array):\n",
    "  array = tf.io.serialize_tensor(array)\n",
    "  return array\n",
    "\n",
    "\n",
    "\n",
    "def parser(serialized_example):\n",
    "    features_description = {'emb': tf.io.FixedLenFeature([], tf.string)}\n",
    "    features = tf.io.parse_single_example(serialized_example, features_description)\n",
    "    features = tf.io.decode_raw(features['emb'], tf.float32)\n",
    "    return features\n",
    "\n",
    "\n",
    "def parse_tfr_element(element):\n",
    "    #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
    "    data = {\n",
    "        'emb' : tf.io.FixedLenFeature([], tf.string),\n",
    "        'track_id' : tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    \n",
    "    content = tf.io.parse_single_example(element, data)\n",
    "\n",
    "    track_id = content['track_id']\n",
    "    emb = content['emb']\n",
    "    \n",
    "\n",
    "    #get our 'feature'-- our image -- and reshape it appropriately\n",
    "    feature = tf.io.parse_tensor(emb, out_type=tf.float32)\n",
    "    return (feature, track_id)\n",
    "\n",
    "\n",
    "def get_dataset(filename):\n",
    "    #create the dataset\n",
    "    dataset = tf.data.TFRecordDataset(filename)\n",
    "\n",
    "    #pass every single feature through our mapping function\n",
    "    dataset = dataset.map(\n",
    "        parse_tfr_element\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55db55f5-ab4a-4325-8764-544eb506d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_dataset(path,dataset=args.embeddings):\n",
    "    tfrecords_path = os.path.join(path,'tfrecords',dataset)\n",
    "    \n",
    "    \n",
    "    tfrecords_path = [os.path.join(tfrecords_path,path) for path in os.listdir(tfrecords_path)]\n",
    "    dataset = get_dataset(tfrecords_path)\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        dataset.as_numpy_iterator(),\n",
    "        columns=['feature', 'track_id']\n",
    "    )\n",
    "        \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        df.feature = df.feature.apply(lambda x: x[0] if x.shape[0] != 0 else None)\n",
    "    except:\n",
    "        print(x)\n",
    "    \n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a9f55ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 15:21:07.074223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8796 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\n",
      "2023-04-24 15:21:07.278961: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [11]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset(args.dataset_path,dataset=args.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09eaba76-bd76-4ff9-aff7-eb913fc46e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  feature  track_id\n",
      "0       [0.0008698702, 0.008201729, 0.018753221, -0.03...    124573\n",
      "1       [-0.00097459555, -0.0051385164, -0.024011323, ...    124574\n",
      "2       [0.039855253, 0.0076441965, -0.00922821, -0.04...    124575\n",
      "3       [0.0029335518, 0.020818433, 0.04269241, -0.016...    124576\n",
      "4       [0.057992022, -0.0510619, -0.048113894, -0.032...    124577\n",
      "...                                                   ...       ...\n",
      "104181  [-0.0080008805, 6.110469e-05, 0.18494046, 0.02...     94245\n",
      "104182  [0.017404526, 0.0132987695, 0.004312843, 0.048...     94246\n",
      "104183  [0.01726994, 0.005624622, 0.10627997, 0.007201...     94247\n",
      "104184  [0.07001238, -3.400445e-05, 0.03528729, 0.0683...     94248\n",
      "104185  [-0.013616562, -0.012981772, -0.0065422454, -0...     94249\n",
      "\n",
      "[104186 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "512cc653-38d8-4535-b902-d59cda07d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c80c731a-298c-4477-b96c-9be6ecc6eaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0008698702, 0.008201729, 0.018753221, -0.03...</td>\n",
       "      <td>124573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.00097459555, -0.0051385164, -0.024011323, ...</td>\n",
       "      <td>124574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.039855253, 0.0076441965, -0.00922821, -0.04...</td>\n",
       "      <td>124575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0029335518, 0.020818433, 0.04269241, -0.016...</td>\n",
       "      <td>124576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.057992022, -0.0510619, -0.048113894, -0.032...</td>\n",
       "      <td>124577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104181</th>\n",
       "      <td>[-0.0080008805, 6.110469e-05, 0.18494046, 0.02...</td>\n",
       "      <td>94245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104182</th>\n",
       "      <td>[0.017404526, 0.0132987695, 0.004312843, 0.048...</td>\n",
       "      <td>94246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104183</th>\n",
       "      <td>[0.01726994, 0.005624622, 0.10627997, 0.007201...</td>\n",
       "      <td>94247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104184</th>\n",
       "      <td>[0.07001238, -3.400445e-05, 0.03528729, 0.0683...</td>\n",
       "      <td>94248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104185</th>\n",
       "      <td>[-0.013616562, -0.012981772, -0.0065422454, -0...</td>\n",
       "      <td>94249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104170 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  feature  track_id\n",
       "0       [0.0008698702, 0.008201729, 0.018753221, -0.03...    124573\n",
       "1       [-0.00097459555, -0.0051385164, -0.024011323, ...    124574\n",
       "2       [0.039855253, 0.0076441965, -0.00922821, -0.04...    124575\n",
       "3       [0.0029335518, 0.020818433, 0.04269241, -0.016...    124576\n",
       "4       [0.057992022, -0.0510619, -0.048113894, -0.032...    124577\n",
       "...                                                   ...       ...\n",
       "104181  [-0.0080008805, 6.110469e-05, 0.18494046, 0.02...     94245\n",
       "104182  [0.017404526, 0.0132987695, 0.004312843, 0.048...     94246\n",
       "104183  [0.01726994, 0.005624622, 0.10627997, 0.007201...     94247\n",
       "104184  [0.07001238, -3.400445e-05, 0.03528729, 0.0683...     94248\n",
       "104185  [-0.013616562, -0.012981772, -0.0065422454, -0...     94249\n",
       "\n",
       "[104170 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dc7f941-56f4-43bc-9d35-8fc233bb2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = pd.read_csv(os.path.join(train_path,\"tracks.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66241ae0-4aae-4ec6-89c6-209098f0ceb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>full_genre_id</th>\n",
       "      <th>labels_1</th>\n",
       "      <th>labels_2</th>\n",
       "      <th>labels_3</th>\n",
       "      <th>labels_4</th>\n",
       "      <th>labels_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48192</td>\n",
       "      <td>[14, '19']</td>\n",
       "      <td>14</td>\n",
       "      <td>14-19</td>\n",
       "      <td>14-19-0</td>\n",
       "      <td>14-19-0-0</td>\n",
       "      <td>14-19-0-0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92014</td>\n",
       "      <td>[14, '19']</td>\n",
       "      <td>14</td>\n",
       "      <td>14-19</td>\n",
       "      <td>14-19-0</td>\n",
       "      <td>14-19-0-0</td>\n",
       "      <td>14-19-0-0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80238</td>\n",
       "      <td>[3, '567']</td>\n",
       "      <td>3</td>\n",
       "      <td>3-567</td>\n",
       "      <td>3-567-0</td>\n",
       "      <td>3-567-0-0</td>\n",
       "      <td>3-567-0-0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117638</td>\n",
       "      <td>[3, '567']</td>\n",
       "      <td>3</td>\n",
       "      <td>3-567</td>\n",
       "      <td>3-567-0</td>\n",
       "      <td>3-567-0-0</td>\n",
       "      <td>3-567-0-0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38991</td>\n",
       "      <td>[14, '19']</td>\n",
       "      <td>14</td>\n",
       "      <td>14-19</td>\n",
       "      <td>14-19-0</td>\n",
       "      <td>14-19-0-0</td>\n",
       "      <td>14-19-0-0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>38976</td>\n",
       "      <td>[14, '19']</td>\n",
       "      <td>14</td>\n",
       "      <td>14-19</td>\n",
       "      <td>14-19-0</td>\n",
       "      <td>14-19-0-0</td>\n",
       "      <td>14-19-0-0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>123630</td>\n",
       "      <td>[14, '19']</td>\n",
       "      <td>14</td>\n",
       "      <td>14-19</td>\n",
       "      <td>14-19-0</td>\n",
       "      <td>14-19-0-0</td>\n",
       "      <td>14-19-0-0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>118651</td>\n",
       "      <td>['3']</td>\n",
       "      <td>3</td>\n",
       "      <td>3-0</td>\n",
       "      <td>3-0-0</td>\n",
       "      <td>3-0-0-0</td>\n",
       "      <td>3-0-0-0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>48197</td>\n",
       "      <td>[14, '19']</td>\n",
       "      <td>14</td>\n",
       "      <td>14-19</td>\n",
       "      <td>14-19-0</td>\n",
       "      <td>14-19-0-0</td>\n",
       "      <td>14-19-0-0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>135718</td>\n",
       "      <td>[14, '19']</td>\n",
       "      <td>14</td>\n",
       "      <td>14-19</td>\n",
       "      <td>14-19-0</td>\n",
       "      <td>14-19-0-0</td>\n",
       "      <td>14-19-0-0-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     track_id full_genre_id  labels_1 labels_2 labels_3   labels_4  \\\n",
       "0       48192    [14, '19']        14    14-19  14-19-0  14-19-0-0   \n",
       "1       92014    [14, '19']        14    14-19  14-19-0  14-19-0-0   \n",
       "2       80238    [3, '567']         3    3-567  3-567-0  3-567-0-0   \n",
       "3      117638    [3, '567']         3    3-567  3-567-0  3-567-0-0   \n",
       "4       38991    [14, '19']        14    14-19  14-19-0  14-19-0-0   \n",
       "..        ...           ...       ...      ...      ...        ...   \n",
       "605     38976    [14, '19']        14    14-19  14-19-0  14-19-0-0   \n",
       "606    123630    [14, '19']        14    14-19  14-19-0  14-19-0-0   \n",
       "607    118651         ['3']         3      3-0    3-0-0    3-0-0-0   \n",
       "608     48197    [14, '19']        14    14-19  14-19-0  14-19-0-0   \n",
       "609    135718    [14, '19']        14    14-19  14-19-0  14-19-0-0   \n",
       "\n",
       "        labels_5  \n",
       "0    14-19-0-0-0  \n",
       "1    14-19-0-0-0  \n",
       "2    3-567-0-0-0  \n",
       "3    3-567-0-0-0  \n",
       "4    14-19-0-0-0  \n",
       "..           ...  \n",
       "605  14-19-0-0-0  \n",
       "606  14-19-0-0-0  \n",
       "607    3-0-0-0-0  \n",
       "608  14-19-0-0-0  \n",
       "609  14-19-0-0-0  \n",
       "\n",
       "[610 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84371fd1-f1f6-42a4-9d4e-209525e6b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = __load_json__(labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95ee8372-0865-4a6f-aa5d-e5508d37c27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'14-0': 2, '3-567': 3, '14-19': 4, '3-0': 5, '14-11': 6}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['label2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4d2ea80-6443-4553-9bd2-5d559a718594",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9bc6e91-7522-41d9-b1fb-0c536e9b6d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a44c5451a340448bcfe7089b4f8df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fda6f7eed3746559b1d6e66ab15cffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_201780/4007447050.py:3: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  tracks_df.loc[:,'labels_2'] = tracks_df.labels_2.astype(str).progress_apply(lambda x: labels['label2'][x])\n"
     ]
    }
   ],
   "source": [
    "tracks_df.loc[:,'labels_1'] = tracks_df.labels_1.astype(str).progress_apply(lambda x: labels['label1'][x])\n",
    "\n",
    "tracks_df.loc[:,'labels_2'] = tracks_df.labels_2.astype(str).progress_apply(lambda x: labels['label2'][x])\n",
    "\n",
    "# tracks_df.loc[:,'labels_3'] = tracks_df.labels_3.astype(str).progress_apply(lambda x: labels['label3'][x])\n",
    "\n",
    "# tracks_df.loc[:,'labels_4'] = tracks_df.labels_4.astype(str).progress_apply(lambda x: labels['label4'][x])\n",
    "\n",
    "# tracks_df.loc[:,'labels_5'] = tracks_df.labels_5.astype(str).progress_apply(lambda x: labels['label5'][x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29b16dec-27e3-4304-8daa-3b3ee7d1ed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = tracks_df.merge(df, on='track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71b60a4c-723b-4a37-a49e-cc0f32ca05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genres_df = tracks_df.drop_duplicates(subset=['labels_5'])[['labels_1','labels_2','labels_3','labels_4','labels_5']]\n",
    "genres_df = tracks_df.drop_duplicates(subset=['labels_2'])[['labels_1','labels_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2997159-fd08-448b-9565-6dade087116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn_hierarchical_classification.classifier import HierarchicalClassifier\n",
    "from sklearn_hierarchical_classification.constants import ROOT\n",
    "from sklearn_hierarchical_classification.metrics import h_fbeta_score, multi_labeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84530afa-5c69-418d-b08e-9bbf2f0cf749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Cria um dicionário que mapeia o ID de cada gênero musical aos IDs de seus subgêneros\n",
    "genre_dict = {\n",
    "    ROOT:genres_df.labels_1.unique().tolist()}\n",
    "\n",
    "def add_node(genre_id,parent_id):\n",
    "    if pd.notna(parent_id):\n",
    "        if parent_id not in genre_dict:\n",
    "            genre_dict[parent_id] = []\n",
    "        genre_dict[parent_id].append(genre_id)\n",
    "\n",
    "\n",
    "\n",
    "for i, row in genres_df.iterrows():\n",
    "    genre_id = row['labels_2']\n",
    "    parent_id = row['labels_1']\n",
    "    add_node(genre_id,parent_id)\n",
    "\n",
    "    # genre_id = row['labels_3']\n",
    "    # parent_id = row['labels_2']\n",
    "    # add_node(genre_id,parent_id)\n",
    "    \n",
    "#     genre_id = row['labels_4']\n",
    "#     parent_id = row['labels_3']\n",
    "#     add_node(genre_id,parent_id)\n",
    "    \n",
    "#     genre_id = row['labels_5']\n",
    "#     parent_id = row['labels_4']\n",
    "    # add_node(genre_id,parent_id)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "# genre_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1cb64ec-7ea0-4d8e-b87b-5214e2b54e03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<ROOT>': [0, 1], 0: [4, 6, 2], 1: [3, 5]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_dict"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4557b43e-2def-448a-a3df-c812ee155c52",
   "metadata": {},
   "source": [
    " Parameters\n",
    "    ----------\n",
    "    base_estimator : classifier object, function, dict, or None\n",
    "        A scikit-learn compatible classifier object implementing \"fit\" and \"predict_proba\" to be used as the\n",
    "        base classifier.\n",
    "        If a callable function is given, it will be called to evaluate which classifier to instantiate for\n",
    "        current node. The function will be called with the current node and the graph instance.\n",
    "        Alternatively, a dictionary mapping classes to classifier objects can be given. In this case,\n",
    "        when building the classifier tree, the dictionary will be consulted and if a key is found matching\n",
    "        a particular node, the base classifier pointed to in the dict will be used. Since this is most often\n",
    "        useful for specifying classifiers on only a handlful of objects, a special \"DEFAULT\" key can be used to\n",
    "        set the base classifier to use as a \"catch all\".\n",
    "        If not provided, a base estimator will be chosen by the framework using various meta-learning\n",
    "        heuristics (WIP).\n",
    "    class_hierarchy : networkx.DiGraph object, or dict-of-dicts adjacency representation (see examples)\n",
    "        A directed graph which represents the target classes and their relations. Must be a tree/DAG (no cycles).\n",
    "        If not provided, this will be initialized during the `fit` operation into a trivial graph structure linking\n",
    "        all classes given in `y` to an artificial \"ROOT\" node.\n",
    "    prediction_depth : \"mlnp\", \"nmlnp\"\n",
    "        Prediction depth requirements. This corresponds to whether we wish the classifier to always terminate at\n",
    "        a leaf node (mandatory leaf-node prediction, \"mlnp\"), or wish to support early termination via some\n",
    "        stopping criteria (non-mandatory leaf-node prediction, \"nmlnp\"). When \"nmlnp\" is specified, the\n",
    "        stopping_criteria parameter is used to control the behaviour of the classifier.\n",
    "    algorithm : \"lcn\", \"lcpn\"\n",
    "        The algorithm type to use for building the hierarchical classification, according to the\n",
    "        taxonomy defined in [1].\n",
    "        \"lcpn\" (which is the default) stands for \"local classifier per parent node\". Under this model,\n",
    "        a multi-class classifier is trained at each parent node, to distinguish between each child nodes.\n",
    "        \"lcn\", which stands for \"local classifier per node\". Under this model, a binary classifier is trained\n",
    "        at each node. Under this model, a further distinction is made based on how the training data set is constructed.\n",
    "        This is controlled by the \"training_strategy\" parameter.\n",
    "    training_strategy: \"exclusive\", \"less_exclusive\", \"inclusive\", \"less_inclusive\",\n",
    "                       \"siblings\", \"exclusive_siblings\", or None.\n",
    "        This parameter is used when the \"algorithm\" parameter is to set to \"lcn\", and dictates how training data\n",
    "        is constructed for training the binary classifier at each node.\n",
    "    stopping_criteria: function, float, or None.\n",
    "        This parameter is used when the \"prediction_depth\" parameter is set to \"nmlnp\", and is used to evaluate\n",
    "        at a given node whether classification should terminate or continue further down the hierarchy.\n",
    "        When set to a float, the prediction will stop if the reported confidence at current classifier is below\n",
    "        the provided value.\n",
    "        When set to a function, the callback function will be called with the current node attributes,\n",
    "        including its metafeatures, and the current classification results.\n",
    "        This allows the user to define arbitrary logic that can decide whether classification should stop at\n",
    "        the current node or continue. The function should return True if classification should continue,\n",
    "        or False if classification should stop at current node.\n",
    "    root : integer, string\n",
    "        The unique identifier for the qualified root node in the class hierarchy. The hierarchical classifier\n",
    "        assumes that the given class hierarchy graph is a rooted DAG, e.g has a single designated root node\n",
    "        of in-degree 0. This node is associated with a special identifier which defaults to a framework provided one,\n",
    "        but can be overridden by user in some cases, e.g if the original taxonomy is already rooted and there\"s no need\n",
    "        for injecting an artifical root node.\n",
    "    progress_wrapper : progress generator or None\n",
    "        If value is set, will attempt to use the given generator to display progress updates. This added functionality\n",
    "        is especially useful within interactive environments (e.g in a testing harness or a Jupyter notebook). Setting\n",
    "        this value will also enable verbose logging. Common values in tqdm are `tqdm_notebook` or `tqdm`\n",
    "    feature_extraction : \"preprocessed\", \"raw\"\n",
    "        Determines the feature extraction policy the classifier uses.\n",
    "        When set to \"raw\", the classifier will expect the raw training examples are passed in to `.fit()` and `.train()`\n",
    "        as X. This means that the base_estimator should point to a sklearn Pipeline that includes feature extraction.\n",
    "        When set to \"preprocessed\", the classifier will expect X to be a pre-computed feature (sparse) matrix.\n",
    "    mlb : MultiLabelBinarizer or None\n",
    "        For multi-label classification, the MultiLabelBinarizer instance that was used for creating the y variable.\n",
    "    mlb_prediction_threshold : float\n",
    "        For multi-label prediction tasks (when `mlb` is set to a MultiLabelBinarizer instance), can define a prediction\n",
    "        score threshold to use for considering a label to be a prediction. Defaults to zero.\n",
    "    use_decision_function : bool\n",
    "        Some classifiers (e.g. sklearn.svm.SVC) expose a `.decision_function()` method which would take in the\n",
    "        feature matrix X and return a set of per-sample scores, corresponding to each label. Setting this to True\n",
    "        would attempt to use this method when it is exposed by the base classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c75fa45-6ea6-465a-ac39-f4e967b1f88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>full_genre_id</th>\n",
       "      <th>labels_1</th>\n",
       "      <th>labels_2</th>\n",
       "      <th>labels_3</th>\n",
       "      <th>labels_4</th>\n",
       "      <th>labels_5</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48192</td>\n",
       "      <td>[14, '19']</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14-19-0</td>\n",
       "      <td>14-19-0-0</td>\n",
       "      <td>14-19-0-0-0</td>\n",
       "      <td>[0.28188887, 0.018675039, 0.0009581049, -0.047...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92014</td>\n",
       "      <td>[14, '19']</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14-19-0</td>\n",
       "      <td>14-19-0-0</td>\n",
       "      <td>14-19-0-0-0</td>\n",
       "      <td>[0.0014705658, -0.040685076, -0.019948969, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80238</td>\n",
       "      <td>[3, '567']</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3-567-0</td>\n",
       "      <td>3-567-0-0</td>\n",
       "      <td>3-567-0-0-0</td>\n",
       "      <td>[0.09746888, -0.016016701, -0.012167622, 0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117638</td>\n",
       "      <td>[3, '567']</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3-567-0</td>\n",
       "      <td>3-567-0-0</td>\n",
       "      <td>3-567-0-0-0</td>\n",
       "      <td>[0.05056459, -0.021571884, -0.030859172, 0.011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38991</td>\n",
       "      <td>[14, '19']</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14-19-0</td>\n",
       "      <td>14-19-0-0</td>\n",
       "      <td>14-19-0-0-0</td>\n",
       "      <td>[-0.013123721, -0.043863863, 0.04856713, 0.083...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>38976</td>\n",
       "      <td>[14, '19']</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14-19-0</td>\n",
       "      <td>14-19-0-0</td>\n",
       "      <td>14-19-0-0-0</td>\n",
       "      <td>[0.104641505, 0.04290545, 0.0416345, 0.1105095...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>123630</td>\n",
       "      <td>[14, '19']</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14-19-0</td>\n",
       "      <td>14-19-0-0</td>\n",
       "      <td>14-19-0-0-0</td>\n",
       "      <td>[0.030703971, 0.012356709, -0.05860837, -0.041...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>118651</td>\n",
       "      <td>['3']</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3-0-0</td>\n",
       "      <td>3-0-0-0</td>\n",
       "      <td>3-0-0-0-0</td>\n",
       "      <td>[0.0019271672, 0.004137248, 0.18107063, -0.089...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>48197</td>\n",
       "      <td>[14, '19']</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14-19-0</td>\n",
       "      <td>14-19-0-0</td>\n",
       "      <td>14-19-0-0-0</td>\n",
       "      <td>[0.021714428, 0.05667938, -0.009912391, 0.0812...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>135718</td>\n",
       "      <td>[14, '19']</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14-19-0</td>\n",
       "      <td>14-19-0-0</td>\n",
       "      <td>14-19-0-0-0</td>\n",
       "      <td>[-0.04340751, -0.003215899, -0.03789528, 0.232...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     track_id full_genre_id  labels_1  labels_2 labels_3   labels_4  \\\n",
       "0       48192    [14, '19']         0         4  14-19-0  14-19-0-0   \n",
       "1       92014    [14, '19']         0         4  14-19-0  14-19-0-0   \n",
       "2       80238    [3, '567']         1         3  3-567-0  3-567-0-0   \n",
       "3      117638    [3, '567']         1         3  3-567-0  3-567-0-0   \n",
       "4       38991    [14, '19']         0         4  14-19-0  14-19-0-0   \n",
       "..        ...           ...       ...       ...      ...        ...   \n",
       "605     38976    [14, '19']         0         4  14-19-0  14-19-0-0   \n",
       "606    123630    [14, '19']         0         4  14-19-0  14-19-0-0   \n",
       "607    118651         ['3']         1         5    3-0-0    3-0-0-0   \n",
       "608     48197    [14, '19']         0         4  14-19-0  14-19-0-0   \n",
       "609    135718    [14, '19']         0         4  14-19-0  14-19-0-0   \n",
       "\n",
       "        labels_5                                            feature  \n",
       "0    14-19-0-0-0  [0.28188887, 0.018675039, 0.0009581049, -0.047...  \n",
       "1    14-19-0-0-0  [0.0014705658, -0.040685076, -0.019948969, 0.0...  \n",
       "2    3-567-0-0-0  [0.09746888, -0.016016701, -0.012167622, 0.024...  \n",
       "3    3-567-0-0-0  [0.05056459, -0.021571884, -0.030859172, 0.011...  \n",
       "4    14-19-0-0-0  [-0.013123721, -0.043863863, 0.04856713, 0.083...  \n",
       "..           ...                                                ...  \n",
       "605  14-19-0-0-0  [0.104641505, 0.04290545, 0.0416345, 0.1105095...  \n",
       "606  14-19-0-0-0  [0.030703971, 0.012356709, -0.05860837, -0.041...  \n",
       "607    3-0-0-0-0  [0.0019271672, 0.004137248, 0.18107063, -0.089...  \n",
       "608  14-19-0-0-0  [0.021714428, 0.05667938, -0.009912391, 0.0812...  \n",
       "609  14-19-0-0-0  [-0.04340751, -0.003215899, -0.03789528, 0.232...  \n",
       "\n",
       "[610 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ac6a590-93f0-4918-9cbb-aeb3564740b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tracks_df.feature.values.tolist(),\n",
    "    tracks_df.labels_2.astype(str).values.tolist(),\n",
    "    test_size=0.05,\n",
    "    random_state=25,\n",
    "    stratify=tracks_df.labels_2.astype(str).values.tolist(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78bc3253-2dca-44dd-9add-052b4550ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ca20cda-03df-41aa-9ebd-02d33d9d4519",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(random_state=42,eval_metric=\"auc\",n_jobs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "870c13d6-8e7b-4dc6-a5e7-c79cd2b7488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all messages, including ones pertaining to debugging\n",
    "xgb.set_config(verbosity=2)\n",
    "\n",
    "# Get current value of global configuration\n",
    "# This is a dict containing all parameters in the global configuration,\n",
    "# including 'verbosity'\n",
    "config = xgb.get_config()\n",
    "assert config['verbosity'] == 2\n",
    "\n",
    "# Example of using the context manager xgb.config_context().\n",
    "# The context manager will restore the previous value of the global\n",
    "# configuration upon exiting.\n",
    "assert xgb.get_config()['verbosity'] == 2  # old value restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f164dc3a-f47e-4256-9e33-450ca1a1fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model.fit(df_train.Feature.values.tolist()[:100], df_train.Label.values.tolist()[:100], eval_set=[(df_val.Feature.values.tolist(), df_val.Label.values.tolist())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "778c2ceb-bc9a-4d66-917a-39304f80ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_estimator = make_pipeline(\n",
    "    TruncatedSVD(n_components=24),\n",
    "    svm.SVC(\n",
    "        kernel=\"rbf\",\n",
    "        probability=True\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fc0b77d-7181-49e2-b45f-b9dab8eebb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_estimator = tree.DecisionTreeClassifier(min_samples_leaf=7,max_features='sqrt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46450016-5a30-4391-b35a-00eee84a50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tree_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b812967f-b474-4ab3-ba33-f1a7a32c7efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = HierarchicalClassifier(\n",
    "    base_estimator=tree_estimator,\n",
    "    class_hierarchy=genre_dict,\n",
    "    progress_wrapper=tqdm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ef42b81-231d-43ef-b669-6c3842848917",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "140bc653-62a7-41bd-8272-bd18eaf3ca02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c345a3fd034f8ca254b56e45b68f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building features:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/anaconda3/lib/python3.10/site-packages/sklearn_hierarchical_classification/classifier.py:287: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  indices = np.flatnonzero(y == node_id)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74116277eaa44c58264e29fa9336197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training base classifiers:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f696d06d-fb13-4dc8-a8ee-f5e175f0bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = os.path.join(train_path,'hsvm.model')\n",
    "pickle.dump(clf, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7042ecd2-5def-49b0-8fb4-b4da71b1400b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn_hierarchical_classification/classifier.py:232\u001b[0m, in \u001b[0;36mHierarchicalClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    229\u001b[0m     path, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recursive_predict(x, root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot)\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 232\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mapply_along_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_classify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn_hierarchical_classification/array.py:28\u001b[0m, in \u001b[0;36mapply_along_rows\u001b[0;34m(func, X)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m     21\u001b[0m         func(X\u001b[38;5;241m.\u001b[39mgetrow(i))\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     23\u001b[0m     ])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# XXX might break vis-a-vis this issue merging: https://github.com/numpy/numpy/pull/8511\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# See discussion over issue with truncated string when using np.apply_along_axis here:\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m#   https://github.com/numpy/numpy/issues/8352\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_along_axis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/ma/extras.py:385\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m outshape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mtake(indlist)\n\u001b[1;32m    384\u001b[0m i\u001b[38;5;241m.\u001b[39mput(indlist, ind)\n\u001b[0;32m--> 385\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m#  if res is a number, then we have a smaller output array\u001b[39;00m\n\u001b[1;32m    387\u001b[0m asscalar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misscalar(res)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn_hierarchical_classification/array.py:29\u001b[0m, in \u001b[0;36mapply_along_rows.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m     21\u001b[0m         func(X\u001b[38;5;241m.\u001b[39mgetrow(i))\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     23\u001b[0m     ])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# XXX might break vis-a-vis this issue merging: https://github.com/numpy/numpy/pull/8511\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# See discussion over issue with truncated string when using np.apply_along_axis here:\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m#   https://github.com/numpy/numpy/issues/8352\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mapply_along_axis(\n\u001b[0;32m---> 29\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     30\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     31\u001b[0m         arr\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m     32\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn_hierarchical_classification/classifier.py:229\u001b[0m, in \u001b[0;36mHierarchicalClassifier.predict.<locals>._classify\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_classify\u001b[39m(x):\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# TODO support multi-label / paths?\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m     path, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn_hierarchical_classification/classifier.py:457\u001b[0m, in \u001b[0;36mHierarchicalClassifier._recursive_predict\u001b[0;34m(self, x, root)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recursive_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, root):\n\u001b[0;32m--> 457\u001b[0m     clf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCLASSIFIER\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    458\u001b[0m     path \u001b[38;5;241m=\u001b[39m [root]\n\u001b[1;32m    459\u001b[0m     path_proba \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyError\u001b[0m: 'classifier'"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "166e08a8-82f6-4723-bb4f-8c2d864a647d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, classification_report(y_test, \u001b[43my_pred\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "76348025-d932-45bc-bfe7-79652b18b0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=['3-0-0', '14-19-0', '14-11-0', '3-0-0', '14-19-0',\n",
       "                   '14-19-0', '14-19-0', '14-19-0', '14-11-0', '3-0-0',\n",
       "                   '14-19-0', '3-567-0', '14-19-0', '14-11-0', '14-19-0',\n",
       "                   '14-19-0', '14-19-0', '3-0-0', '14-19-0', '14-19-0',\n",
       "                   '14-19-0', '3-0-0', '14-19-0', '14-19-0', '14-19-0',\n",
       "                   '14-19-0', '14-19-0', '14-19-0', '14-19-0', '14-19-0',\n",
       "                   '14-11-0'],\n",
       "             mask=False,\n",
       "       fill_value='N/A',\n",
       "            dtype='<U7')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ac9554d0-59fa-4f75-a3f8-fc154501195c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-567-0',\n",
       " '3-0-0',\n",
       " '14-11-0',\n",
       " '14-19-0',\n",
       " '14-19-0',\n",
       " '3-0-0',\n",
       " '14-19-0',\n",
       " '3-0-0',\n",
       " '14-19-0',\n",
       " '3-0-0',\n",
       " '14-19-0',\n",
       " '3-567-0',\n",
       " '14-19-0',\n",
       " '14-11-0',\n",
       " '14-19-0',\n",
       " '14-19-0',\n",
       " '14-11-0',\n",
       " '14-0-0',\n",
       " '3-0-0',\n",
       " '14-19-0',\n",
       " '3-567-0',\n",
       " '14-19-0',\n",
       " '14-19-0',\n",
       " '14-19-0',\n",
       " '14-11-0',\n",
       " '14-0-0',\n",
       " '3-0-0',\n",
       " '14-0-0',\n",
       " '14-19-0',\n",
       " '14-19-0',\n",
       " '14-11-0']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "720d356e-8c67-482a-a18c-12c9d338d138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cabou\n"
     ]
    }
   ],
   "source": [
    "print('cabou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75c716-d477-4876-ae7f-5214f3c2b8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd16ab4-3f2c-4c73-a157-d2db0da6598f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
