{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9fb572-bb1b-435a-b329-5c295067093a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 17:32:14.230622: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-24 17:32:14.914879: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64:/usr/local/cuda-11.7/lib64:\n",
      "2023-02-24 17:32:14.914982: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64:/usr/local/cuda-11.7/lib64:\n",
      "2023-02-24 17:32:14.914988: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0541e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, tfrecords_path, epochs, batch_size):\n",
    "        self.tfrecords_path = tfrecords_path\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def list_files(self):\n",
    "        return [os.path.join(tfrecords_path,file_path) for file_path in os.listdir(tfrecords_path)]\n",
    "\n",
    "    def build(self):\n",
    "        files = self.list_files()\n",
    "\n",
    "        print(\"build_tf record: files_count: {} / batch_size: {} / epochs: {}\".format(len(files), self.batch_size, self.epochs))\n",
    "\n",
    "        ds = tf.data.TFRecordDataset(files, num_parallel_reads=multiprocessing.cpu_count())\n",
    "        \n",
    "        '''''\n",
    "            Shuffle and reapeat\n",
    "        '''''\n",
    "        \n",
    "        \n",
    "        ds = ds.shuffle(buffer_size=1024 * 1 * 10)\n",
    "        ds = ds.repeat(count=self.epochs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''''\n",
    "            Map and batch\n",
    "        '''''\n",
    "        \n",
    "                      \n",
    "        ds = ds.map(self.__parse__, num_parallel_calls=None)\n",
    "        ds = ds.batch(self.batch_size,drop_remainder=False)\n",
    "        \n",
    "        \n",
    "                      \n",
    "        ds = ds.prefetch(buffer_size=5)\n",
    "                      \n",
    "\n",
    "        return ds\n",
    "    \n",
    "   \n",
    "    @staticmethod\n",
    "    def __parse__(example):\n",
    "        parsed = tf.parse_single_example(example, features={\n",
    "            'emb' : tf.io.FixedLenFeature([], tf.string),\n",
    "            'label' : tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True)\n",
    "        })\n",
    "        \n",
    "        content = tf.io.parse_single_example(element, data)\n",
    "\n",
    "        label = tf.cast(content['label'], tf.int32)\n",
    "        label_hot = tf.one_hot(label1[0], label1[1])\n",
    "        \n",
    "        emb = content['emb']\n",
    "        #get our 'feature'\n",
    "        feature = tf.io.parse_tensor(emb, out_type=tf.float32)\n",
    "\n",
    "        inp = {'emb': feature}\n",
    "        out = {'global_output': label_hot}\n",
    "\n",
    "        return inp, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0369afd-5070-44a7-b14c-d5a58c762969",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n",
    "        value = value.numpy() # get value of tensor\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a floast_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_array(array):\n",
    "  array = tf.io.serialize_tensor(array)\n",
    "  return array\n",
    "\n",
    "\n",
    "\n",
    "def parser(serialized_example):\n",
    "    features_description = {'emb': tf.io.FixedLenFeature([], tf.string)}\n",
    "    features = tf.io.parse_single_example(serialized_example, features_description)\n",
    "    features = tf.io.decode_raw(features['emb'], tf.float32)\n",
    "    return features\n",
    "\n",
    "\n",
    "def parse_tfr_element(element):\n",
    "    #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
    "    data = {\n",
    "        'emb' : tf.io.FixedLenFeature([], tf.string),\n",
    "        'label' : tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "    }\n",
    "    \n",
    "    content = tf.io.parse_single_example(element, data)\n",
    "\n",
    "    label = content['label']\n",
    "    emb = content['emb']\n",
    "    \n",
    "\n",
    "    #get our 'feature'-- our image -- and reshape it appropriately\n",
    "    feature = tf.io.parse_tensor(emb, out_type=tf.float32)\n",
    "    return (feature, label)\n",
    "\n",
    "\n",
    "def get_dataset(filename):\n",
    "    #create the dataset\n",
    "    dataset = tf.data.TFRecordDataset(filename)\n",
    "\n",
    "    #pass every single feature through our mapping function\n",
    "    dataset = dataset.map(\n",
    "        parse_tfr_element\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e7f8e9-f33c-47a8-9762-d5dffafd2dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = pd.Series({\n",
    "    \"root_dir\":\"/mnt/disks/data/\",\n",
    "    \"embeddings\":\"music_style\",\n",
    "    \"train_id\": \"global_mini_test\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d41cbf5-cd66-4206-8dfd-da45299b415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_path = \"/mnt/disks/data/fma/trains\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2081da1-af33-4f3e-941b-4651799ce87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "train_path = os.path.join(job_path,args.train_id)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "base_path = os.path.join(args.root_dir,\"fma\")\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "models_path = os.path.join(args.root_dir,\"models\")\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "metadata_path = os.path.join(base_path,\"fma_metadata\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55db55f5-ab4a-4325-8764-544eb506d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_dataset(train_path,dataset='train'):\n",
    "    tfrecords_path = os.path.join(train_path,'tfrecords',dataset)\n",
    "    \n",
    "    \n",
    "    tfrecords_path = [os.path.join(tfrecords_path,path) for path in os.listdir(tfrecords_path)]\n",
    "    dataset = get_dataset(tfrecords_path)\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        dataset.as_numpy_iterator(),\n",
    "        columns=['Feature', 'Label']\n",
    "    )\n",
    "        \n",
    "    df.Label = df.Label.apply(lambda x: x[0])\n",
    "    df.Feature = df.Feature.apply(lambda x: x[0])\n",
    "    \n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a9f55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_dataset(train_path,dataset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "515f2598-79c2-4bc3-8a1c-93e2ba25efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = load_dataset(train_path,dataset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa7725da-7284-447d-a127-4d1a6a28d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = load_dataset(train_path,dataset='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "662672a2-64cc-4111-9d38-ac25e54f23b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.04681793, 0.023077885, -0.06364204, -0.036...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.01089413, -0.037857268, -0.026134571, -0.0...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1028996, 0.030849427, -0.015898084, -0.0258...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.06418469, 0.041289672, -0.07045288, -0.0300...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.023684343, 0.04708304, 0.036143806, -0.0369...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>[0.06455163, -0.02210641, -0.042902213, -0.018...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>[0.06932942, -0.033957988, 0.069253765, -0.034...</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>[0.16392896, -0.027170211, 0.3902943, -0.00760...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>[0.27844694, -0.046748284, 0.110625125, -0.089...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>[0.025291288, 0.017221838, -0.049740847, -0.00...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Feature  Label\n",
       "0    [-0.04681793, 0.023077885, -0.06364204, -0.036...     84\n",
       "1    [-0.01089413, -0.037857268, -0.026134571, -0.0...     14\n",
       "2    [0.1028996, 0.030849427, -0.015898084, -0.0258...      1\n",
       "3    [0.06418469, 0.041289672, -0.07045288, -0.0300...     29\n",
       "4    [0.023684343, 0.04708304, 0.036143806, -0.0369...     16\n",
       "..                                                 ...    ...\n",
       "119  [0.06455163, -0.02210641, -0.042902213, -0.018...     27\n",
       "120  [0.06932942, -0.033957988, 0.069253765, -0.034...     71\n",
       "121  [0.16392896, -0.027170211, 0.3902943, -0.00760...      1\n",
       "122  [0.27844694, -0.046748284, 0.110625125, -0.089...     65\n",
       "123  [0.025291288, 0.017221838, -0.049740847, -0.00...     78\n",
       "\n",
       "[124 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b48cdcae-98bd-4967-9e37-486b85e85554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1722e8ce-e1aa-4760-8626-a58eb78abbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(random_state=42,n_jobs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "147a3b80-644e-4418-9bd0-3feb8ac011e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.62843\n",
      "[1]\tvalidation_0-auc:0.66962\n",
      "[2]\tvalidation_0-auc:0.70263\n",
      "[3]\tvalidation_0-auc:0.72982\n",
      "[4]\tvalidation_0-auc:0.74737\n",
      "[5]\tvalidation_0-auc:0.75828\n",
      "[6]\tvalidation_0-auc:0.75988\n",
      "[7]\tvalidation_0-auc:0.75904\n",
      "[8]\tvalidation_0-auc:0.76220\n",
      "[9]\tvalidation_0-auc:0.75965\n",
      "[10]\tvalidation_0-auc:0.76232\n",
      "[11]\tvalidation_0-auc:0.76407\n",
      "[12]\tvalidation_0-auc:0.76608\n",
      "[13]\tvalidation_0-auc:0.76429\n",
      "[14]\tvalidation_0-auc:0.76722\n",
      "[15]\tvalidation_0-auc:0.77141\n",
      "[16]\tvalidation_0-auc:0.76959\n",
      "[17]\tvalidation_0-auc:0.77066\n",
      "[18]\tvalidation_0-auc:0.77501\n",
      "[19]\tvalidation_0-auc:0.77439\n",
      "[20]\tvalidation_0-auc:0.77558\n",
      "[21]\tvalidation_0-auc:0.77649\n",
      "[22]\tvalidation_0-auc:0.77709\n",
      "[23]\tvalidation_0-auc:0.77695\n",
      "[24]\tvalidation_0-auc:0.77746\n",
      "[25]\tvalidation_0-auc:0.77654\n",
      "[26]\tvalidation_0-auc:0.77676\n",
      "[27]\tvalidation_0-auc:0.77797\n",
      "[28]\tvalidation_0-auc:0.77804\n",
      "[29]\tvalidation_0-auc:0.78014\n",
      "[30]\tvalidation_0-auc:0.77961\n",
      "[31]\tvalidation_0-auc:0.77990\n",
      "[32]\tvalidation_0-auc:0.77953\n",
      "[33]\tvalidation_0-auc:0.77943\n",
      "[34]\tvalidation_0-auc:0.77941\n",
      "[35]\tvalidation_0-auc:0.77834\n",
      "[36]\tvalidation_0-auc:0.77842\n",
      "[37]\tvalidation_0-auc:0.77730\n",
      "[38]\tvalidation_0-auc:0.77715\n",
      "[39]\tvalidation_0-auc:0.77830\n",
      "[40]\tvalidation_0-auc:0.77983\n",
      "[41]\tvalidation_0-auc:0.78030\n",
      "[42]\tvalidation_0-auc:0.78040\n",
      "[43]\tvalidation_0-auc:0.78002\n",
      "[44]\tvalidation_0-auc:0.78008\n",
      "[45]\tvalidation_0-auc:0.78049\n",
      "[46]\tvalidation_0-auc:0.78036\n",
      "[47]\tvalidation_0-auc:0.78072\n",
      "[48]\tvalidation_0-auc:0.78035\n",
      "[49]\tvalidation_0-auc:0.78114\n",
      "[50]\tvalidation_0-auc:0.78080\n",
      "[51]\tvalidation_0-auc:0.78039\n",
      "[52]\tvalidation_0-auc:0.78061\n",
      "[53]\tvalidation_0-auc:0.77992\n",
      "[54]\tvalidation_0-auc:0.78011\n",
      "[55]\tvalidation_0-auc:0.78032\n",
      "[56]\tvalidation_0-auc:0.78032\n",
      "[57]\tvalidation_0-auc:0.78113\n",
      "[58]\tvalidation_0-auc:0.78080\n",
      "[59]\tvalidation_0-auc:0.78135\n",
      "[60]\tvalidation_0-auc:0.78267\n",
      "[61]\tvalidation_0-auc:0.78183\n",
      "[62]\tvalidation_0-auc:0.78214\n",
      "[63]\tvalidation_0-auc:0.78235\n",
      "[64]\tvalidation_0-auc:0.78179\n",
      "[65]\tvalidation_0-auc:0.78297\n",
      "[66]\tvalidation_0-auc:0.78299\n",
      "[67]\tvalidation_0-auc:0.78264\n",
      "[68]\tvalidation_0-auc:0.78237\n",
      "[69]\tvalidation_0-auc:0.78183\n",
      "[70]\tvalidation_0-auc:0.78157\n",
      "[71]\tvalidation_0-auc:0.78150\n",
      "[72]\tvalidation_0-auc:0.78192\n",
      "[73]\tvalidation_0-auc:0.78194\n",
      "[74]\tvalidation_0-auc:0.78227\n",
      "[75]\tvalidation_0-auc:0.78170\n",
      "[76]\tvalidation_0-auc:0.78185\n",
      "[77]\tvalidation_0-auc:0.78255\n",
      "[78]\tvalidation_0-auc:0.78249\n",
      "[79]\tvalidation_0-auc:0.78236\n",
      "[80]\tvalidation_0-auc:0.78214\n",
      "[81]\tvalidation_0-auc:0.78207\n",
      "[82]\tvalidation_0-auc:0.78131\n",
      "[83]\tvalidation_0-auc:0.78207\n",
      "[84]\tvalidation_0-auc:0.78173\n",
      "[85]\tvalidation_0-auc:0.78193\n",
      "[86]\tvalidation_0-auc:0.78137\n",
      "[87]\tvalidation_0-auc:0.78082\n",
      "[88]\tvalidation_0-auc:0.78130\n",
      "[89]\tvalidation_0-auc:0.78172\n",
      "[90]\tvalidation_0-auc:0.78075\n",
      "[91]\tvalidation_0-auc:0.78075\n",
      "[92]\tvalidation_0-auc:0.78048\n",
      "[93]\tvalidation_0-auc:0.78111\n",
      "[94]\tvalidation_0-auc:0.78048\n",
      "[95]\tvalidation_0-auc:0.78081\n",
      "[96]\tvalidation_0-auc:0.78075\n",
      "[97]\tvalidation_0-auc:0.78026\n",
      "[98]\tvalidation_0-auc:0.77963\n",
      "[99]\tvalidation_0-auc:0.77943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=20, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(df_train.Feature.values.tolist(), df_train.Label.values.tolist(), eval_metric=\"auc\",\n",
    "        eval_set=[(df_val.Feature.values.tolist(), df_val.Label.values.tolist())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07831e78-5949-46cd-be04-1cd2b934be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f059c7cf-84a9-42fc-be39-25832ea6c361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593.2903225806451"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(df_test.Feature.values.tolist())\n",
    "\n",
    "mean_squared_error(df_test.Label.values.tolist(), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "039ed246-d415-4838-87fd-0d9335b9a6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bruno/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bruno/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.370968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.333487</td>\n",
       "      <td>0.347911</td>\n",
       "      <td>0.337561</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.298337</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.317591</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.000000  0.000000  0.000000    1.000000\n",
       "1              0.133333  0.400000  0.200000    5.000000\n",
       "2              0.000000  0.000000  0.000000    1.000000\n",
       "3              0.000000  0.000000  0.000000    1.000000\n",
       "4              0.000000  0.000000  0.000000    1.000000\n",
       "...                 ...       ...       ...         ...\n",
       "93             1.000000  1.000000  1.000000    1.000000\n",
       "94             1.000000  1.000000  1.000000    1.000000\n",
       "accuracy       0.370968  0.370968  0.370968    0.370968\n",
       "macro avg      0.333487  0.347911  0.337561  124.000000\n",
       "weighted avg   0.298337  0.370968  0.317591  124.000000\n",
       "\n",
       "[98 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(df_test.Label.values.tolist(), y_pred,output_dict=True)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f50ad9-b826-4ed0-89d3-b870c2db6a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
