{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d9fb572-bb1b-435a-b329-5c295067093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1500e7c-e11f-4e7e-9fb3-ad06f08ca7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = pd.Series({\n",
    "    \"root_dir\":\"/mnt/disks/data/\",\n",
    "    \"dataset_path\":\"/mnt/disks/data/fma/fma_large\",\n",
    "    \"embeddings\":\"music_style\",\n",
    "    \"train_id\": \"hierarchical_single\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de612e34-baf4-4d04-aa16-3a931e2ae188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_path = \"/mnt/disks/data/fma/trains\"\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "train_path = os.path.join(job_path,args.train_id)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "base_path = os.path.join(args.root_dir,\"fma\")\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "models_path = os.path.join(args.root_dir,\"models\")\n",
    "\n",
    "\n",
    "metadata_path_fma = os.path.join(base_path,\"fma_metadata\")\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "metadata_file = os.path.join(train_path,\"metadata.json\")\n",
    "\n",
    "\n",
    "labels_file = os.path.join(train_path,\"labels.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e024261-df17-48aa-8876-e8cea69e4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def __load_json__(path):\n",
    "    with open(path, 'r') as f:\n",
    "        tmp = json.loads(f.read())\n",
    "\n",
    "    return tmp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0541e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, tfrecords_path, epochs, batch_size):\n",
    "        self.tfrecords_path = tfrecords_path\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def list_files(self):\n",
    "        return [os.path.join(tfrecords_path,file_path) for file_path in os.listdir(tfrecords_path)]\n",
    "\n",
    "    def build(self):\n",
    "        files = self.list_files()\n",
    "\n",
    "        print(\"build_tf record: files_count: {} / batch_size: {} / epochs: {}\".format(len(files), self.batch_size, self.epochs))\n",
    "\n",
    "        ds = tf.data.TFRecordDataset(files, num_parallel_reads=multiprocessing.cpu_count())\n",
    "                      \n",
    "\n",
    "        return ds\n",
    "    \n",
    "   \n",
    "    @staticmethod\n",
    "    def __parse__(example):\n",
    "        parsed = tf.parse_single_example(example, features={\n",
    "            'emb' : tf.io.FixedLenFeature([], tf.string),\n",
    "            'track_id' : tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True)\n",
    "        })\n",
    "        \n",
    "        content = tf.io.parse_single_example(element, data)\n",
    "\n",
    "        label = tf.cast(content['track_id'], tf.int32)\n",
    "        label_hot = tf.one_hot(label1[0], label1[1])\n",
    "        \n",
    "        emb = content['emb']\n",
    "        #get our 'feature'\n",
    "        feature = tf.io.parse_tensor(emb, out_type=tf.float32)\n",
    "\n",
    "        inp = {'emb': feature}\n",
    "        out = {'global_output': label_hot}\n",
    "\n",
    "        return inp, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0369afd-5070-44a7-b14c-d5a58c762969",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n",
    "        value = value.numpy() # get value of tensor\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a floast_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_array(array):\n",
    "  array = tf.io.serialize_tensor(array)\n",
    "  return array\n",
    "\n",
    "\n",
    "\n",
    "def parser(serialized_example):\n",
    "    features_description = {'emb': tf.io.FixedLenFeature([], tf.string)}\n",
    "    features = tf.io.parse_single_example(serialized_example, features_description)\n",
    "    features = tf.io.decode_raw(features['emb'], tf.float32)\n",
    "    return features\n",
    "\n",
    "\n",
    "def parse_tfr_element(element):\n",
    "    #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
    "    data = {\n",
    "        'emb' : tf.io.FixedLenFeature([], tf.string),\n",
    "        'track_id' : tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    \n",
    "    content = tf.io.parse_single_example(element, data)\n",
    "\n",
    "    track_id = content['track_id']\n",
    "    emb = content['emb']\n",
    "    \n",
    "\n",
    "    #get our 'feature'-- our image -- and reshape it appropriately\n",
    "    feature = tf.io.parse_tensor(emb, out_type=tf.float32)\n",
    "    return (feature, track_id)\n",
    "\n",
    "\n",
    "def get_dataset(filename):\n",
    "    #create the dataset\n",
    "    dataset = tf.data.TFRecordDataset(filename)\n",
    "\n",
    "    #pass every single feature through our mapping function\n",
    "    dataset = dataset.map(\n",
    "        parse_tfr_element\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55db55f5-ab4a-4325-8764-544eb506d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_dataset(path,dataset=args.embeddings):\n",
    "    tfrecords_path = os.path.join(path,'tfrecords',dataset)\n",
    "    \n",
    "    \n",
    "    tfrecords_path = [os.path.join(tfrecords_path,path) for path in os.listdir(tfrecords_path)]\n",
    "    dataset = get_dataset(tfrecords_path)\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        dataset.as_numpy_iterator(),\n",
    "        columns=['feature', 'track_id']\n",
    "    )\n",
    "        \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        df.feature = df.feature.apply(lambda x: x[0] if x.shape[0] != 0 else None)\n",
    "    except:\n",
    "        print(x)\n",
    "    \n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(args.dataset_path,dataset=args.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eaba76-bd76-4ff9-aff7-eb913fc46e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512cc653-38d8-4535-b902-d59cda07d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c731a-298c-4477-b96c-9be6ecc6eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7f941-56f4-43bc-9d35-8fc233bb2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = pd.read_csv(os.path.join(train_path,\"tracks.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66241ae0-4aae-4ec6-89c6-209098f0ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84371fd1-f1f6-42a4-9d4e-209525e6b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = __load_json__(labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d2ea80-6443-4553-9bd2-5d559a718594",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc6e91-7522-41d9-b1fb-0c536e9b6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracks_df.loc[:,'labels_1'] = tracks_df.labels_1.astype(str).progress_apply(lambda x: labels['label1'][x])\n",
    "\n",
    "# tracks_df.loc[:,'labels_2'] = tracks_df.labels_2.astype(str).progress_apply(lambda x: labels['label2'][x])\n",
    "\n",
    "# tracks_df.loc[:,'labels_3'] = tracks_df.labels_3.astype(str).progress_apply(lambda x: labels['label3'][x])\n",
    "\n",
    "# tracks_df.loc[:,'labels_4'] = tracks_df.labels_4.astype(str).progress_apply(lambda x: labels['label4'][x])\n",
    "\n",
    "# tracks_df.loc[:,'labels_5'] = tracks_df.labels_5.astype(str).progress_apply(lambda x: labels['label5'][x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b16dec-27e3-4304-8daa-3b3ee7d1ed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = tracks_df.merge(df, on='track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b60a4c-723b-4a37-a49e-cc0f32ca05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genres_df = tracks_df.drop_duplicates(subset=['labels_5'])[['labels_1','labels_2','labels_3','labels_4','labels_5']]\n",
    "genres_df = tracks_df.drop_duplicates(subset=['labels_2'])[['labels_1','labels_2','labels_3','labels_4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2997159-fd08-448b-9565-6dade087116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn_hierarchical_classification.classifier import HierarchicalClassifier\n",
    "from sklearn_hierarchical_classification.constants import ROOT\n",
    "from sklearn_hierarchical_classification.metrics import h_fbeta_score, multi_labeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84530afa-5c69-418d-b08e-9bbf2f0cf749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Cria um dicionário que mapeia o ID de cada gênero musical aos IDs de seus subgêneros\n",
    "genre_dict = {\n",
    "    ROOT:genres_df.labels_1.unique().tolist()}\n",
    "\n",
    "def add_node(genre_id,parent_id):\n",
    "    if pd.notna(parent_id):\n",
    "        if parent_id not in genre_dict:\n",
    "            genre_dict[parent_id] = []\n",
    "        genre_dict[parent_id].append(genre_id)\n",
    "\n",
    "\n",
    "\n",
    "for i, row in genres_df.iterrows():\n",
    "    genre_id = row['labels_2']\n",
    "    parent_id = row['labels_1']\n",
    "    add_node(genre_id,parent_id)\n",
    "\n",
    "    genre_id = row['labels_3']\n",
    "    parent_id = row['labels_2']\n",
    "    add_node(genre_id,parent_id)\n",
    "    \n",
    "    genre_id = row['labels_4']\n",
    "    parent_id = row['labels_3']\n",
    "    add_node(genre_id,parent_id)\n",
    "    \n",
    "#     genre_id = row['labels_5']\n",
    "#     parent_id = row['labels_4']\n",
    "    # add_node(genre_id,parent_id)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "# genre_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cb64ec-7ea0-4d8e-b87b-5214e2b54e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "genre_dict"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4557b43e-2def-448a-a3df-c812ee155c52",
   "metadata": {},
   "source": [
    " Parameters\n",
    "    ----------\n",
    "    base_estimator : classifier object, function, dict, or None\n",
    "        A scikit-learn compatible classifier object implementing \"fit\" and \"predict_proba\" to be used as the\n",
    "        base classifier.\n",
    "        If a callable function is given, it will be called to evaluate which classifier to instantiate for\n",
    "        current node. The function will be called with the current node and the graph instance.\n",
    "        Alternatively, a dictionary mapping classes to classifier objects can be given. In this case,\n",
    "        when building the classifier tree, the dictionary will be consulted and if a key is found matching\n",
    "        a particular node, the base classifier pointed to in the dict will be used. Since this is most often\n",
    "        useful for specifying classifiers on only a handlful of objects, a special \"DEFAULT\" key can be used to\n",
    "        set the base classifier to use as a \"catch all\".\n",
    "        If not provided, a base estimator will be chosen by the framework using various meta-learning\n",
    "        heuristics (WIP).\n",
    "    class_hierarchy : networkx.DiGraph object, or dict-of-dicts adjacency representation (see examples)\n",
    "        A directed graph which represents the target classes and their relations. Must be a tree/DAG (no cycles).\n",
    "        If not provided, this will be initialized during the `fit` operation into a trivial graph structure linking\n",
    "        all classes given in `y` to an artificial \"ROOT\" node.\n",
    "    prediction_depth : \"mlnp\", \"nmlnp\"\n",
    "        Prediction depth requirements. This corresponds to whether we wish the classifier to always terminate at\n",
    "        a leaf node (mandatory leaf-node prediction, \"mlnp\"), or wish to support early termination via some\n",
    "        stopping criteria (non-mandatory leaf-node prediction, \"nmlnp\"). When \"nmlnp\" is specified, the\n",
    "        stopping_criteria parameter is used to control the behaviour of the classifier.\n",
    "    algorithm : \"lcn\", \"lcpn\"\n",
    "        The algorithm type to use for building the hierarchical classification, according to the\n",
    "        taxonomy defined in [1].\n",
    "        \"lcpn\" (which is the default) stands for \"local classifier per parent node\". Under this model,\n",
    "        a multi-class classifier is trained at each parent node, to distinguish between each child nodes.\n",
    "        \"lcn\", which stands for \"local classifier per node\". Under this model, a binary classifier is trained\n",
    "        at each node. Under this model, a further distinction is made based on how the training data set is constructed.\n",
    "        This is controlled by the \"training_strategy\" parameter.\n",
    "    training_strategy: \"exclusive\", \"less_exclusive\", \"inclusive\", \"less_inclusive\",\n",
    "                       \"siblings\", \"exclusive_siblings\", or None.\n",
    "        This parameter is used when the \"algorithm\" parameter is to set to \"lcn\", and dictates how training data\n",
    "        is constructed for training the binary classifier at each node.\n",
    "    stopping_criteria: function, float, or None.\n",
    "        This parameter is used when the \"prediction_depth\" parameter is set to \"nmlnp\", and is used to evaluate\n",
    "        at a given node whether classification should terminate or continue further down the hierarchy.\n",
    "        When set to a float, the prediction will stop if the reported confidence at current classifier is below\n",
    "        the provided value.\n",
    "        When set to a function, the callback function will be called with the current node attributes,\n",
    "        including its metafeatures, and the current classification results.\n",
    "        This allows the user to define arbitrary logic that can decide whether classification should stop at\n",
    "        the current node or continue. The function should return True if classification should continue,\n",
    "        or False if classification should stop at current node.\n",
    "    root : integer, string\n",
    "        The unique identifier for the qualified root node in the class hierarchy. The hierarchical classifier\n",
    "        assumes that the given class hierarchy graph is a rooted DAG, e.g has a single designated root node\n",
    "        of in-degree 0. This node is associated with a special identifier which defaults to a framework provided one,\n",
    "        but can be overridden by user in some cases, e.g if the original taxonomy is already rooted and there\"s no need\n",
    "        for injecting an artifical root node.\n",
    "    progress_wrapper : progress generator or None\n",
    "        If value is set, will attempt to use the given generator to display progress updates. This added functionality\n",
    "        is especially useful within interactive environments (e.g in a testing harness or a Jupyter notebook). Setting\n",
    "        this value will also enable verbose logging. Common values in tqdm are `tqdm_notebook` or `tqdm`\n",
    "    feature_extraction : \"preprocessed\", \"raw\"\n",
    "        Determines the feature extraction policy the classifier uses.\n",
    "        When set to \"raw\", the classifier will expect the raw training examples are passed in to `.fit()` and `.train()`\n",
    "        as X. This means that the base_estimator should point to a sklearn Pipeline that includes feature extraction.\n",
    "        When set to \"preprocessed\", the classifier will expect X to be a pre-computed feature (sparse) matrix.\n",
    "    mlb : MultiLabelBinarizer or None\n",
    "        For multi-label classification, the MultiLabelBinarizer instance that was used for creating the y variable.\n",
    "    mlb_prediction_threshold : float\n",
    "        For multi-label prediction tasks (when `mlb` is set to a MultiLabelBinarizer instance), can define a prediction\n",
    "        score threshold to use for considering a label to be a prediction. Defaults to zero.\n",
    "    use_decision_function : bool\n",
    "        Some classifiers (e.g. sklearn.svm.SVC) expose a `.decision_function()` method which would take in the\n",
    "        feature matrix X and return a set of per-sample scores, corresponding to each label. Setting this to True\n",
    "        would attempt to use this method when it is exposed by the base classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75fa45-6ea6-465a-ac39-f4e967b1f88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6a590-93f0-4918-9cbb-aeb3564740b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tracks_df.feature.values.tolist(),\n",
    "    tracks_df.labels_4.astype(str).values.tolist(),\n",
    "    test_size=0.05,\n",
    "    random_state=25,\n",
    "    stratify=tracks_df.labels_4.astype(str).values.tolist(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c2ceb-bc9a-4d66-917a-39304f80ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_estimator = make_pipeline(\n",
    "    TruncatedSVD(n_components=24),\n",
    "    svm.SVC(\n",
    "        kernel=\"rbf\",\n",
    "        probability=True\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0b77d-7181-49e2-b45f-b9dab8eebb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_estimator = tree.DecisionTreeClassifier(min_samples_leaf=7,max_features='sqrt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46450016-5a30-4391-b35a-00eee84a50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = svm_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b812967f-b474-4ab3-ba33-f1a7a32c7efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = HierarchicalClassifier(\n",
    "    base_estimator=estimator,\n",
    "    class_hierarchy=genre_dict,\n",
    "    progress_wrapper=tqdm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef42b81-231d-43ef-b669-6c3842848917",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140bc653-62a7-41bd-8272-bd18eaf3ca02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f696d06d-fb13-4dc8-a8ee-f5e175f0bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = os.path.join(train_path,'hsvm.model')\n",
    "pickle.dump(model, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7042ecd2-5def-49b0-8fb4-b4da71b1400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "166e08a8-82f6-4723-bb4f-8c2d864a647d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      14-0-0       0.00      0.00      0.00         3\n",
      "     14-11-0       0.75      0.60      0.67         5\n",
      "     14-19-0       0.52      0.79      0.63        14\n",
      "       3-0-0       0.20      0.17      0.18         6\n",
      "     3-567-0       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.52        31\n",
      "   macro avg       0.49      0.38      0.40        31\n",
      "weighted avg       0.49      0.52      0.47        31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bruno/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bruno/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "76348025-d932-45bc-bfe7-79652b18b0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=['3-0-0', '14-19-0', '14-11-0', '3-0-0', '14-19-0',\n",
       "                   '14-19-0', '14-19-0', '14-19-0', '14-11-0', '3-0-0',\n",
       "                   '14-19-0', '3-567-0', '14-19-0', '14-11-0', '14-19-0',\n",
       "                   '14-19-0', '14-19-0', '3-0-0', '14-19-0', '14-19-0',\n",
       "                   '14-19-0', '3-0-0', '14-19-0', '14-19-0', '14-19-0',\n",
       "                   '14-19-0', '14-19-0', '14-19-0', '14-19-0', '14-19-0',\n",
       "                   '14-11-0'],\n",
       "             mask=False,\n",
       "       fill_value='N/A',\n",
       "            dtype='<U7')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ac9554d0-59fa-4f75-a3f8-fc154501195c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-567-0',\n",
       " '3-0-0',\n",
       " '14-11-0',\n",
       " '14-19-0',\n",
       " '14-19-0',\n",
       " '3-0-0',\n",
       " '14-19-0',\n",
       " '3-0-0',\n",
       " '14-19-0',\n",
       " '3-0-0',\n",
       " '14-19-0',\n",
       " '3-567-0',\n",
       " '14-19-0',\n",
       " '14-11-0',\n",
       " '14-19-0',\n",
       " '14-19-0',\n",
       " '14-11-0',\n",
       " '14-0-0',\n",
       " '3-0-0',\n",
       " '14-19-0',\n",
       " '3-567-0',\n",
       " '14-19-0',\n",
       " '14-19-0',\n",
       " '14-19-0',\n",
       " '14-11-0',\n",
       " '14-0-0',\n",
       " '3-0-0',\n",
       " '14-0-0',\n",
       " '14-19-0',\n",
       " '14-19-0',\n",
       " '14-11-0']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "720d356e-8c67-482a-a18c-12c9d338d138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cabou\n"
     ]
    }
   ],
   "source": [
    "print('cabou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75c716-d477-4876-ae7f-5214f3c2b8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd16ab4-3f2c-4c73-a157-d2db0da6598f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
