{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4843caad-aa4a-420d-81f8-dcc1189318c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 11:30:41.409878: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-26 11:30:42.040078: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from math import ceil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f36844-bc15-46f4-8994-6744042b62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "194b058a-a5c5-4d87-817d-aeb9e833cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = pd.Series({\n",
    "    \"root_dir\":\"/mnt/disks/data/\",\n",
    "    \"dataset_path\":\"/mnt/disks/data/fma/fma_large\",\n",
    "    \"embeddings\":\"music_style\",\n",
    "    \"sequence_size\": 1280,\n",
    "    \"train_id\": \"hierarchical_multilabel_sample\",\n",
    "    'sample_size': 0.1\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87f3fe25-bd80-4976-ba77-ab30589a9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_path = \"/mnt/disks/data/fma/trains\"\n",
    "\n",
    "\n",
    "job_path = os.path.join(base_path,args.train_id)\n",
    "\n",
    "\n",
    "tfrecord_path = os.path.join(job_path,\"tfrecords\")\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "base_path = os.path.join(args.root_dir,\"fma\")\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "models_path = os.path.join(args.root_dir,\"models\")\n",
    "\n",
    "\n",
    "metadata_path_fma = os.path.join(base_path,\"fma_metadata\")\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "metadata_path = os.path.join(job_path,\"metadata.json\")\n",
    "\n",
    "\n",
    "categories_labels_path = os.path.join(job_path,\"labels.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffea2009-fdc3-425e-bd6b-a67696ab24da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def __load_json__(path):\n",
    "    with open(path, 'r') as f:\n",
    "        tmp = json.loads(f.read())\n",
    "\n",
    "    return tmp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b413d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dir(path):\n",
    "    # checking if the directory demo_folder2 \n",
    "    # exist or not.\n",
    "    if not os.path.isdir(path):\n",
    "\n",
    "        # if the demo_folder2 directory is \n",
    "        # not present then create it.\n",
    "        os.makedirs(path)\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dccd7294-d081-4124-993b-26f5b3a8ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(job_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be2f0fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dir(job_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbd961-6913-4179-a6c3-fc93d2ea305b",
   "metadata": {},
   "source": [
    "## Análise do tracks.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a2799b4-eca6-4233-8782-a17e4cb7856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = os.path.join(metadata_path_fma,\"tracks_genres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e828426-7527-4d3b-abcf-d70ce19dc62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks = pd.read_csv(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87c737e3-7d78-47f0-859f-112f682245f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[21]]'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tracks.full_genre_id.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2f87a83-e718-42a9-8734-e50fa84f6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_literal_val(labels):\n",
    "    labels = [label for label in ast.literal_eval(labels)]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d90a2d7-8c2f-4520-a363-8f85f1e43021",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks[\"full_genre_id\"] = df_tracks.full_genre_id.apply(lambda x : extract_literal_val(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13ea402f-660b-4b95-8f91-563c01971578",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks = df_tracks.sample(frac=args.sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "69d80106-b330-4749-8aee-d2fbc451ecfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_genre_id\n",
       "[[21]]                                            296\n",
       "[[15]]                                            268\n",
       "[[1, 38], [30, 38], [38], [41, 38], [247, 38]]    173\n",
       "[[12]]                                            158\n",
       "[[38]]                                            135\n",
       "                                                 ... \n",
       "[[7, 20], [15], [181, 15]]                          1\n",
       "[[10], [12], [103, 17]]                             1\n",
       "[[14], [15], [38]]                                  1\n",
       "[[58, 12], [76, 10], [311, 13]]                     1\n",
       "[[311, 13], [362, 10]]                              1\n",
       "Name: count, Length: 2530, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tracks.full_genre_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f09d82a-f990-4c04-bf6f-614b8bcfd6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover linhas com genre_id vazio\n",
    "df_tracks = df_tracks[df_tracks['full_genre_id'].map(len) > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "96ac1ba9-a138-41b5-a127-f1900385126a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "track_id                                                       96993\n",
       "full_genre_id                      [[15, 183], [42, 15], [38], [15]]\n",
       "file_path               /mnt/disks/data/fma/fma_large/096/096993.mp3\n",
       "labels_genre_id    [[183, 15, 0, 0, 0], [15, 42, 0, 0, 0], [38, 0...\n",
       "Name: 63225, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tracks.iloc[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a297dde3-9a11-4d9f-943e-2d09694a2bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_size(labels):\n",
    "    return max([len(label) for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "90068602-0c57-4e10-bd9b-64cd1c8d8ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_size = df_tracks.full_genre_id.apply(lambda x: get_label_size(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e59cd652-b8ed-4c33-988e-79082a9a7c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86488    2\n",
       "82099    2\n",
       "50000    3\n",
       "90646    2\n",
       "72844    2\n",
       "        ..\n",
       "42354    2\n",
       "71509    2\n",
       "43957    2\n",
       "93353    2\n",
       "87671    1\n",
       "Name: full_genre_id, Length: 10419, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "18733907-5a23-46aa-8d9a-90c8fb556bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, 4, 5])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_size.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "70f2351f-2f55-4979-84c2-0cb142887a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_size = max(labels_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e1f6ac31-ca09-4e44-a120-cd4534cd851e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74827c2e-072a-4213-9b96-f7bb24dee80e",
   "metadata": {},
   "source": [
    "### Parse of label to structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "093a84f2-25d1-4f95-81e5-c51e73933e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for parse label to sctructure of hierarhical scheme\n",
    "\n",
    "def parse_label(label,label_size):\n",
    "    # label = label.split('-')\n",
    "    # preencher com 0 no caso de haver menos de 5 níveis\n",
    "    labels = np.zeros(label_size, dtype=int)\n",
    "    for i, label in enumerate(label[::-1]):\n",
    "        if i == 5:\n",
    "            break\n",
    "        # Aqui você pode fazer a conversão do label em um índice inteiro usando um dicionário ou outro método\n",
    "        # Neste exemplo, estou apenas usando a posição da label na lista como índice\n",
    "        labels[i] = label\n",
    "    return labels\n",
    "\n",
    "\n",
    "def parse_labels(labels,label_size=5):\n",
    "    cv_labels = []\n",
    "    for label in labels:\n",
    "        cv_labels.append(parse_label(label,label_size))\n",
    "    return cv_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a234f76a-5822-42d4-aba2-cfc7fce1fe05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "track_id_                                               96993\n",
       "full_genre_id               [[15, 183], [42, 15], [38], [15]]\n",
       "file_path        /mnt/disks/data/fma/fma_large/096/096993.mp3\n",
       "Name: 63225, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tracks.iloc[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "286776a0-1518-4eaa-b227-ff5b4176f1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[183, 15]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tracks.full_genre_id.iloc[150][0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a6733e73-9e54-4e89-a37f-081a4d9365f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([183,  15,   0,   0,   0]),\n",
       " array([15, 42,  0,  0,  0]),\n",
       " array([38,  0,  0,  0,  0]),\n",
       " array([15,  0,  0,  0,  0])]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_labels(df_tracks.full_genre_id.iloc[150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2a6adb21-c145-4c82-ba79-798d02c7d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_labels = df_tracks.full_genre_id.apply(lambda x: parse_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6407ba13-b11c-4eef-89bd-18be9b99a3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86488                                 [[21, 100, 0, 0, 0]]\n",
       "82099             [[15, 286, 0, 0, 0], [21, 542, 0, 0, 0]]\n",
       "50000             [[12, 25, 0, 0, 0], [12, 25, 109, 0, 0]]\n",
       "90646    [[21, 0, 0, 0, 0], [2, 46, 0, 0, 0], [21, 539,...\n",
       "72844    [[17, 0, 0, 0, 0], [17, 94, 0, 0, 0], [9, 137,...\n",
       "                               ...                        \n",
       "42354    [[12, 0, 0, 0, 0], [12, 25, 0, 0, 0], [12, 27,...\n",
       "71509    [[1235, 18, 0, 0, 0], [15, 42, 0, 0, 0], [38, ...\n",
       "43957                [[15, 0, 0, 0, 0], [10, 76, 0, 0, 0]]\n",
       "93353                [[38, 0, 0, 0, 0], [38, 47, 0, 0, 0]]\n",
       "87671                 [[15, 0, 0, 0, 0], [38, 0, 0, 0, 0]]\n",
       "Name: full_genre_id, Length: 10419, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5981a36f-cb76-4d1f-8bfe-7e58f3b002e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks['labels_genre_id'] = parsed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9eead49d-684f-4a0c-9605-838422a3687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks.rename(columns={'track_id_':'track_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2959d2e9-b85c-41a5-80e4-2b0ea2ce6d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_labels(all_labels):\n",
    "    df = pd.DataFrame({'labels': []})\n",
    "    cv_labels = []\n",
    "    for labels in all_labels:\n",
    "        if len(labels) > 1:\n",
    "            cv_labels.append(labels[0])\n",
    "            for label in labels:\n",
    "                cv_labels.append(label)\n",
    "    df['labels'] = cv_labels\n",
    "    return df.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "369bc133-80a6-4a94-a6f7-f1bace44ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_labels(all_labels,level=4):\n",
    "    df = pd.DataFrame({'labels': []})\n",
    "    cv_labels = []\n",
    "    for labels in all_labels:\n",
    "        for label in labels:\n",
    "            if label[level] != 0:\n",
    "                cv_labels.append(label[level])\n",
    "    df['labels'] = cv_labels\n",
    "    return df.labels.unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "929e06b5-739c-4fbd-90aa-a41429cc2156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 15, 12, 2, 17, 9, 38, 4, 10, 5, 1235, 13, 3, 20, 14, 8, 183]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique_labels(df_tracks.labels_genre_id.values,level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d1e5f547-34ba-4d8d-b3ef-7d7eebc578fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_4 = {'level4': get_unique_labels(df_tracks.labels_genre_id.values)}\n",
    "level_3 = {'level3': get_unique_labels(df_tracks.labels_genre_id.values,level=3)}\n",
    "level_2 = {'level2': get_unique_labels(df_tracks.labels_genre_id.values,level=2)}\n",
    "level_1 = {'level1': get_unique_labels(df_tracks.labels_genre_id.values,level=1)}\n",
    "level_0 = {'level0': get_unique_labels(df_tracks.labels_genre_id.values,level=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dbcda972-9206-44a3-bd05-7617854efca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 15, 12, 2, 17, 9, 38, 4, 10, 5, 1235, 13, 3, 20, 14, 8, 183]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique_labels(df_tracks.labels_genre_id.values,level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b891c1a5-55db-4ff5-b413-2639e889fece",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_df = pd.read_csv(os.path.join(metadata_path_fma,'genres.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "98cdbbf8-1ca7-45e7-a28a-65b4178e419a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  38,    2,    3,    4,    5,   20,    8,    9,   10,   14,   12,\n",
       "         13,   15,   17, 1235,   21])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.top_level.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1c4326bd-6d17-4857-b29c-9fc868e7561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_name(labels, genres_df):\n",
    "    full_name = []\n",
    "    genre_root = \"\"\n",
    "    for genre in labels:\n",
    "        genre_df = genres_df[genres_df['genre_id'] == int(genre)]\n",
    "        if genre_df.empty:\n",
    "            genre_name = genre_root\n",
    "        else:\n",
    "            genre_name = genre_df.title.values.tolist()[0]\n",
    "            genre_root = genre_name\n",
    "        full_name.append(genre_name)\n",
    "    full_name = '>'.join(full_name)\n",
    "    return full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5fa16276-5e41-4ee5-821b-dabd1620c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "level4_name = get_labels_name(level_4['level4'], genres_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b31230a6-7116-4836-af74-a3626a9c3090",
   "metadata": {},
   "outputs": [],
   "source": [
    "level3_name = get_labels_name(level_3['level3'], genres_df)\n",
    "level2_name = get_labels_name(level_2['level2'], genres_df)\n",
    "level1_name = get_labels_name(level_1['level1'], genres_df)\n",
    "level0_name = get_labels_name(level_0['level0'], genres_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2d2099b6-cf3b-47ae-bca2-7d2cc8a1cb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hip-Hop>Electronic>Rock>International>Folk>Country>Experimental>Jazz>Pop>Classical>Instrumental>Easy Listening>Blues>Spoken>Soul-RnB>Old-Time / Historic>Glitch'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level0_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ced721-6c30-46da-95b5-a28b84b6a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __create_labels__(categories_df):\n",
    "    data = {\n",
    "        \"label1\": {},\n",
    "        \"label2\": {},\n",
    "        \"label3\": {},\n",
    "        \"label4\": {},\n",
    "        \"label5\": {},\n",
    "        \"label1_inverse\": [],\n",
    "        \"label2_inverse\": [],\n",
    "        \"label3_inverse\": [],\n",
    "        \"label4_inverse\": [],\n",
    "        \"label5_inverse\": [],\n",
    "        \"label1_name\": {},\n",
    "        \"label2_name\": {},\n",
    "        \"label3_name\": {},\n",
    "        \"label4_name\": {},\n",
    "        \"label5_name\": {},\n",
    "    }\n",
    "\n",
    "    idx = 0\n",
    "    for id_x, cat in enumerate(set(categories_df.level1.values.tolist())):\n",
    "        data['label1'][cat] = idx\n",
    "        data['label1_inverse'].append(cat)\n",
    "        data['label1_count'] = idx + 1\n",
    "        idx += 1\n",
    "\n",
    "    for id_x, cat in enumerate(set(categories_df.level2.values.tolist())):\n",
    "        data['label2'][cat] = idx\n",
    "        data['label2_inverse'].append(cat)\n",
    "        data['label2_count'] = idx + 1\n",
    "        idx += 1\n",
    "    for id_x, cat in enumerate(set(categories_df.level3.values.tolist())):\n",
    "        data['label3'][cat] = idx\n",
    "        data['label3_inverse'].append(cat)\n",
    "        data['label3_count'] = idx + 1\n",
    "        idx += 1\n",
    "\n",
    "    for id_x, cat in enumerate(set(categories_df.level4.values.tolist())):\n",
    "        data['label4'][cat] = idx\n",
    "        data['label4_inverse'].append(cat)\n",
    "        data['label4_count'] = idx + 1\n",
    "        idx += 1\n",
    "    for idx, cat in enumerate(set(categories_df.level5.values.tolist())):\n",
    "        data['label5'][cat] = idx\n",
    "        data['label5_inverse'].append(cat)\n",
    "        data['label5_count'] = idx + 1\n",
    "        idx += 1\n",
    "    for cat5, cat1, cat2, cat3, cat4, name5 in categories_df.values:\n",
    "        name1 = '>'.join(name5.split('>')[:1])\n",
    "        name2 = '>'.join(name5.split('>')[:2])\n",
    "        name3 = '>'.join(name5.split('>')[:3])\n",
    "        name4 = '>'.join(name5.split('>')[:4])\n",
    "        \n",
    "        data['label1_name'][cat1] = name1\n",
    "        data['label2_name'][cat2] = name2\n",
    "        data['label3_name'][cat3] = name3\n",
    "        data['label4_name'][cat4] = name4\n",
    "        data['label5_name'][cat5] = name5\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ccc947-b7ae-464d-a325-d61aa3cf5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(categories_labels_path, 'w+') as f:\n",
    "    f.write(json.dumps(__create_labels__(categories_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3778cc5d-7def-4a1d-9f5b-b141bd08356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =__create_labels__(categories_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b67e97-0813-492e-8323-f8588ca8d120",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'337': 0,\n",
       " '92': 1,\n",
       " '85': 2,\n",
       " '442': 3,\n",
       " '619': 4,\n",
       " '188': 5,\n",
       " '13': 6,\n",
       " '651': 7,\n",
       " '113': 8,\n",
       " '502': 9,\n",
       " '42': 10,\n",
       " '2': 11,\n",
       " '810': 12,\n",
       " '176': 13,\n",
       " '296': 14,\n",
       " '32': 15,\n",
       " '167': 16,\n",
       " '89': 17,\n",
       " '174': 18,\n",
       " '240': 19,\n",
       " '27': 20,\n",
       " '88': 21,\n",
       " '539': 22,\n",
       " '404': 23,\n",
       " '180': 24,\n",
       " '1032': 25,\n",
       " '4': 26,\n",
       " '314': 27,\n",
       " '41': 28,\n",
       " '117': 29,\n",
       " '12': 30,\n",
       " '428': 31,\n",
       " '360': 32,\n",
       " '138': 33,\n",
       " '22': 34,\n",
       " '20': 35,\n",
       " '602': 36,\n",
       " '74': 37,\n",
       " '695': 38,\n",
       " '401': 39,\n",
       " '179': 40,\n",
       " '107': 41,\n",
       " '36': 42,\n",
       " '9': 43,\n",
       " '8': 44,\n",
       " '100': 45,\n",
       " '185': 46,\n",
       " '468': 47,\n",
       " '493': 48,\n",
       " '181': 49,\n",
       " '441': 50,\n",
       " '362': 51,\n",
       " '90': 52,\n",
       " '187': 53,\n",
       " '101': 54,\n",
       " '49': 55,\n",
       " '30': 56,\n",
       " '81': 57,\n",
       " '182': 58,\n",
       " '63': 59,\n",
       " '1235': 60,\n",
       " '189': 61,\n",
       " '111': 62,\n",
       " '125': 63,\n",
       " '186': 64,\n",
       " '58': 65,\n",
       " '38': 66,\n",
       " '297': 67,\n",
       " '808': 68,\n",
       " '456': 69,\n",
       " '76': 70,\n",
       " '542': 71,\n",
       " '19': 72,\n",
       " '444': 73,\n",
       " '71': 74,\n",
       " '567': 75,\n",
       " '359': 76,\n",
       " '247': 77,\n",
       " '46': 78,\n",
       " '538': 79,\n",
       " '169': 80,\n",
       " '440': 81,\n",
       " '514': 82,\n",
       " '1': 83,\n",
       " '77': 84,\n",
       " '3': 85,\n",
       " '16': 86,\n",
       " '177': 87,\n",
       " '98': 88,\n",
       " '70': 89,\n",
       " '171': 90,\n",
       " '659': 91,\n",
       " '322': 92,\n",
       " '443': 93,\n",
       " '811': 94,\n",
       " '173': 95,\n",
       " '439': 96,\n",
       " '504': 97,\n",
       " '906': 98,\n",
       " '43': 99,\n",
       " '214': 100,\n",
       " '137': 101,\n",
       " '83': 102,\n",
       " '378': 103,\n",
       " '47': 104,\n",
       " '37': 105,\n",
       " '26': 106,\n",
       " '495': 107,\n",
       " '21': 108,\n",
       " '400': 109,\n",
       " '45': 110,\n",
       " '250': 111,\n",
       " '184': 112,\n",
       " '236': 113,\n",
       " '31': 114,\n",
       " '232': 115,\n",
       " '11': 116,\n",
       " '1193': 117,\n",
       " '103': 118,\n",
       " '741': 119,\n",
       " '524': 120,\n",
       " '377': 121,\n",
       " '94': 122,\n",
       " '17': 123,\n",
       " '15': 124,\n",
       " '102': 125,\n",
       " '53': 126,\n",
       " '170': 127,\n",
       " '1156': 128,\n",
       " '465': 129,\n",
       " '25': 130,\n",
       " '183': 131,\n",
       " '267': 132,\n",
       " '361': 133,\n",
       " '64': 134,\n",
       " '693': 135,\n",
       " '109': 136,\n",
       " '118': 137,\n",
       " '491': 138,\n",
       " '7': 139,\n",
       " '172': 140,\n",
       " '1060': 141,\n",
       " '6': 142,\n",
       " '311': 143,\n",
       " '66': 144,\n",
       " '10': 145,\n",
       " '86': 146,\n",
       " '18': 147,\n",
       " '763': 148,\n",
       " '580': 149,\n",
       " '14': 150,\n",
       " '166': 151,\n",
       " '5': 152,\n",
       " '33': 153,\n",
       " '65': 154,\n",
       " '286': 155,\n",
       " '130': 156,\n",
       " '224': 157,\n",
       " '79': 158,\n",
       " '97': 159}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['label1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676dd2f5-aa10-4a54-8542-fb86b770de22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['label1_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "34af3ff3-11d0-415f-8736-519e5911ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfr_element(element):\n",
    "    #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
    "    data = {\n",
    "        'emb' : tf.io.FixedLenFeature([], tf.string),\n",
    "        'track_id' : tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    \n",
    "    content = tf.io.parse_single_example(element, data)\n",
    "\n",
    "    track_id = content['track_id']\n",
    "    emb = content['emb']\n",
    "    \n",
    "\n",
    "    #get our 'feature'-- our image -- and reshape it appropriately\n",
    "    feature = tf.io.parse_tensor(emb, out_type=tf.float32)\n",
    "    return (feature, track_id)\n",
    "\n",
    "\n",
    "def get_dataset(filename):\n",
    "    #create the dataset\n",
    "    dataset = tf.data.TFRecordDataset(filename)\n",
    "\n",
    "    #pass every single feature through our mapping function\n",
    "    dataset = dataset.map(\n",
    "        parse_tfr_element\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4580514b-0be9-4de5-a8d3-f987ba73134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_dataset(path,dataset=args.embeddings):\n",
    "    tfrecords_path = os.path.join(path,'tfrecords',dataset)\n",
    "    tfrecords_path = [os.path.join(tfrecords_path, path) for path in os.listdir(tfrecords_path)]\n",
    "    dataset = get_dataset(tfrecords_path)\n",
    "    df = pd.DataFrame(\n",
    "        dataset.as_numpy_iterator(),\n",
    "        columns=['feature', 'track_id']\n",
    "    )\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    try:\n",
    "        df.feature = df.feature.apply(lambda x: x[0] if x.shape[0] != 0 else None)\n",
    "    except:\n",
    "        print(x)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ecb34052-60dd-40db-9ba4-0a92c17f9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __split_data__(group, percentage=0.1):\n",
    "    if len(group) == 1:\n",
    "        return group, group\n",
    "\n",
    "    shuffled = shuffle(group.values)\n",
    "    finish_test = int(ceil(len(group) * percentage))\n",
    "\n",
    "    first = pd.DataFrame(shuffled[:finish_test], columns=group.columns)\n",
    "    second = pd.DataFrame(shuffled[finish_test:], columns=group.columns)\n",
    "\n",
    "    return first, second\n",
    "\n",
    "def get_labels(labels_dict, labels, level='label1'):\n",
    "    cv_labels = []\n",
    "    for label in labels:\n",
    "        cv_labels.append(labels_dict[level][label])\n",
    "    return cv_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f6b687c1-660a-4e8c-a76a-6b2a85ae4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_dataset(df_tracks, labels_dict):\n",
    "    \n",
    "#     dataset_testset_path = os.path.join(tfrecord_path,'test')\n",
    "#     dataset_validationset_path = os.path.join(tfrecord_path,'val')\n",
    "#     dataset_trainset_path = os.path.join(tfrecord_path,'train')\n",
    "    \n",
    "    df = load_dataset(args.dataset_path, dataset=args.embeddings)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    df_tracks = df_tracks.merge(df, on='track_id')\n",
    "\n",
    "    df_tracks.loc[:,'labels_1'] = df_tracks.labels_1.progress_apply(lambda x: get_labels(labels_dict, x, level='label1'))\n",
    "    df_tracks.loc[:,'labels_2'] = df_tracks.labels_2.progress_apply(lambda x: get_labels(labels_dict, x, level='label2'))\n",
    "    df_tracks.loc[:,'labels_3'] = df_tracks.labels_3.progress_apply(lambda x: get_labels(labels_dict, x, level='label3'))\n",
    "    df_tracks.loc[:,'labels_4'] = df_tracks.labels_4.progress_apply(lambda x: get_labels(labels_dict, x, level='label4'))\n",
    "    df_tracks.loc[:,'labels_5'] = df_tracks.labels_5.progress_apply(lambda x: get_labels(labels_dict, x, level='label5'))\n",
    "\n",
    "    tests = []\n",
    "    trains = []\n",
    "    validations = []\n",
    "    groups = df_tracks.groupby(\"labels_5\")\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    items_count = 0\n",
    "    total = len(groups)\n",
    "    total_items = len(df_tracks)\n",
    "    oversampling_size = 30  # int(group_sizes.mean() + group_sizes.std() * 2)\n",
    "    print(f\"oversampling_size: {oversampling_size}\")\n",
    "\n",
    "    for code, group in groups:\n",
    "        test, train_to_split = __split_data__(group, 0.01)  # 10%\n",
    "        train_to_split = train_to_split\n",
    "        validation, train = __split_data__(train_to_split, 0.01)  # %1\n",
    "\n",
    "        tests.append(test)\n",
    "        validations.append(validation)\n",
    "\n",
    "        ## this increase the numner of samples when classes has low quantity\n",
    "        count_train = len(train)\n",
    "        if count_train < oversampling_size:\n",
    "            train = train.sample(oversampling_size, replace=True)\n",
    "\n",
    "        trains.append(train)\n",
    "\n",
    "        count += 1\n",
    "        items_count += count_train\n",
    "        \n",
    "    df_test = pd.concat(tests, sort=False).sample(frac=1).reset_index(drop=True)\n",
    "    # .to_csv(dataset_testset_path, index=False,quoting=csv.QUOTE_ALL)\n",
    "    df_val = pd.concat(validations, sort=False).sample(frac=1).reset_index(drop=True)\n",
    "    df_train = pd.concat(trains, sort=False).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return df_train, df_test, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2935be5c-052f-4477-863a-acf7a160b9ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec881dfb89b4030ad15c3c362a10243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'374'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train, df_test, df_val \u001b[38;5;241m=\u001b[39m \u001b[43mselect_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_tracks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[133], line 13\u001b[0m, in \u001b[0;36mselect_dataset\u001b[0;34m(df_tracks, labels_dict)\u001b[0m\n\u001b[1;32m      9\u001b[0m df\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m df_tracks \u001b[38;5;241m=\u001b[39m df_tracks\u001b[38;5;241m.\u001b[39mmerge(df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m df_tracks\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_tracks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m df_tracks\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_tracks\u001b[38;5;241m.\u001b[39mlabels_2\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_labels(labels_dict, x, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel2\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     15\u001b[0m df_tracks\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_3\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_tracks\u001b[38;5;241m.\u001b[39mlabels_3\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_labels(labels_dict, x, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel3\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/fma_hc/lib/python3.11/site-packages/tqdm/std.py:920\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    922\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/fma_hc/lib/python3.11/site-packages/pandas/core/series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4529\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fma_hc/lib/python3.11/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fma_hc/lib/python3.11/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/fma_hc/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/fma_hc/lib/python3.11/site-packages/tqdm/std.py:915\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    914\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[133], line 13\u001b[0m, in \u001b[0;36mselect_dataset.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m df\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m df_tracks \u001b[38;5;241m=\u001b[39m df_tracks\u001b[38;5;241m.\u001b[39mmerge(df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m df_tracks\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_tracks\u001b[38;5;241m.\u001b[39mlabels_1\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mget_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m df_tracks\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_tracks\u001b[38;5;241m.\u001b[39mlabels_2\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_labels(labels_dict, x, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel2\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     15\u001b[0m df_tracks\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_3\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_tracks\u001b[38;5;241m.\u001b[39mlabels_3\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_labels(labels_dict, x, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel3\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[130], line 16\u001b[0m, in \u001b[0;36mget_labels\u001b[0;34m(labels_dict, labels, level)\u001b[0m\n\u001b[1;32m     14\u001b[0m cv_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[0;32m---> 16\u001b[0m     cv_labels\u001b[38;5;241m.\u001b[39mappend(\u001b[43mlabels_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_labels\n",
      "\u001b[0;31mKeyError\u001b[0m: '374'"
     ]
    }
   ],
   "source": [
    "df_train, df_test, df_val = select_dataset(df_tracks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ca3a658-7d5e-4bf6-a5e6-40dfe0b4813b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>full_genre_id</th>\n",
       "      <th>labels_1</th>\n",
       "      <th>labels_2</th>\n",
       "      <th>labels_3</th>\n",
       "      <th>labels_4</th>\n",
       "      <th>labels_5</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115627</td>\n",
       "      <td>[12, 25, 89]</td>\n",
       "      <td>8</td>\n",
       "      <td>135</td>\n",
       "      <td>164</td>\n",
       "      <td>373</td>\n",
       "      <td>84</td>\n",
       "      <td>[0.021790445, 0.29853275, -0.026587656, 0.0666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146915</td>\n",
       "      <td>[38, 41]</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>371</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.1287572, -0.04188484, -0.020825902, 0.01465...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144872</td>\n",
       "      <td>[38, 250]</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>218</td>\n",
       "      <td>385</td>\n",
       "      <td>126</td>\n",
       "      <td>[0.084029794, -7.178386e-05, -0.053328514, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66741</td>\n",
       "      <td>[1235, 18]</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>217</td>\n",
       "      <td>312</td>\n",
       "      <td>72</td>\n",
       "      <td>[0.11808327, 0.10941779, 0.40051472, -0.049361...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121728</td>\n",
       "      <td>[1235, 107]</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>206</td>\n",
       "      <td>331</td>\n",
       "      <td>93</td>\n",
       "      <td>[-0.03590433, 0.020767719, -0.03485803, -0.030...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102226</th>\n",
       "      <td>96841</td>\n",
       "      <td>[38, 41]</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>371</td>\n",
       "      <td>12</td>\n",
       "      <td>[-0.03989613, -0.004323274, 0.02414892, 0.0396...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102227</th>\n",
       "      <td>19591</td>\n",
       "      <td>[8]</td>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>267</td>\n",
       "      <td>338</td>\n",
       "      <td>14</td>\n",
       "      <td>[0.056298267, -0.018925885, -0.04787774, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102228</th>\n",
       "      <td>5166</td>\n",
       "      <td>[12]</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>236</td>\n",
       "      <td>442</td>\n",
       "      <td>69</td>\n",
       "      <td>[0.031009829, 0.012057076, -0.03138266, 0.0563...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102229</th>\n",
       "      <td>106189</td>\n",
       "      <td>[15, 286]</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>160</td>\n",
       "      <td>393</td>\n",
       "      <td>87</td>\n",
       "      <td>[0.009615977, 0.12510824, 0.010890921, 0.00987...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102230</th>\n",
       "      <td>85548</td>\n",
       "      <td>[1235, 107]</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>206</td>\n",
       "      <td>331</td>\n",
       "      <td>93</td>\n",
       "      <td>[0.011825353, 0.0042595766, 0.12860407, -0.050...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102231 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       track_id full_genre_id labels_1 labels_2 labels_3 labels_4 labels_5  \\\n",
       "0        115627  [12, 25, 89]        8      135      164      373       84   \n",
       "1        146915      [38, 41]        1       78      158      371       12   \n",
       "2        144872     [38, 250]        1       92      218      385      126   \n",
       "3         66741    [1235, 18]        4      105      217      312       72   \n",
       "4        121728   [1235, 107]        4       25      206      331       93   \n",
       "...         ...           ...      ...      ...      ...      ...      ...   \n",
       "102226    96841      [38, 41]        1       78      158      371       12   \n",
       "102227    19591           [8]        5       68      267      338       14   \n",
       "102228     5166          [12]        8      128      236      442       69   \n",
       "102229   106189     [15, 286]        2      132      160      393       87   \n",
       "102230    85548   [1235, 107]        4       25      206      331       93   \n",
       "\n",
       "                                                  feature  \n",
       "0       [0.021790445, 0.29853275, -0.026587656, 0.0666...  \n",
       "1       [0.1287572, -0.04188484, -0.020825902, 0.01465...  \n",
       "2       [0.084029794, -7.178386e-05, -0.053328514, -0....  \n",
       "3       [0.11808327, 0.10941779, 0.40051472, -0.049361...  \n",
       "4       [-0.03590433, 0.020767719, -0.03485803, -0.030...  \n",
       "...                                                   ...  \n",
       "102226  [-0.03989613, -0.004323274, 0.02414892, 0.0396...  \n",
       "102227  [0.056298267, -0.018925885, -0.04787774, -0.01...  \n",
       "102228  [0.031009829, 0.012057076, -0.03138266, 0.0563...  \n",
       "102229  [0.009615977, 0.12510824, 0.010890921, 0.00987...  \n",
       "102230  [0.011825353, 0.0042595766, 0.12860407, -0.050...  \n",
       "\n",
       "[102231 rows x 8 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a882ada1-9d1f-4fc1-9d4c-c2c7a0279557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  ### Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n",
    "        value = value.numpy() # get value of tensor\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "def _float_feature(value):\n",
    "  ### Returns a floast_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _int64List_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  ###  Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_array(array):\n",
    "    array = tf.io.serialize_tensor(array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "847ca375-63be-4f96-8bbe-9346d827c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_single_music(data,labels):\n",
    "    track_id, _, cat1, cat2, cat3, cat4, cat5, music = data\n",
    "    \n",
    "    \n",
    "    label1 = np.array([cat1, labels['label1_count']], np.int64)\n",
    "    label2 = np.array([cat2, labels['label2_count']], np.int64)\n",
    "    label3 = np.array([cat3, labels['label3_count']], np.int64)\n",
    "    label4 = np.array([cat4, labels['label4_count']], np.int64)\n",
    "    label5 = np.array([cat5, labels['label5_count']], np.int64)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #define the dictionary -- the structure -- of our single example\n",
    "    data = {\n",
    "        'label1': _int64List_feature(label1),\n",
    "        'label2': _int64List_feature(label2),\n",
    "        'label3': _int64List_feature(label3),\n",
    "        'label4': _int64List_feature(label4),\n",
    "        'label5': _int64List_feature(label5),\n",
    "        # 'features' : _bytes_feature(serialize_array(music)),\n",
    "        'features' : _float_feature(music),\n",
    "        'track_id' : _int64_feature(track_id)\n",
    "    }\n",
    "    #create an Example, wrapping the single features\n",
    "    out = tf.train.Example(features=tf.train.Features(feature=data))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75a8419a-fe56-4e6b-818b-7198f9370311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tf_record(df,tf_path='val'):\n",
    "    create_dir(tf_path)\n",
    "    \n",
    "    \n",
    "    batch_size = 1024 * 50 # 50k records from each file batch\n",
    "    count = 0\n",
    "    total = math.ceil(len(df) / batch_size)\n",
    "\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch_df = df[i:i+batch_size]\n",
    "        \n",
    "        tfrecords = [parse_single_music(data, labels) for data in batch_df.values]\n",
    "        \n",
    "        path = f\"{tf_path}/{str(count).zfill(10)}.tfrecord\"\n",
    "        \n",
    "        #with tf.python_io.TFRecordWriter(path) as writer:\n",
    "        with tf.io.TFRecordWriter(path) as writer:\n",
    "            for tfrecord in tfrecords:\n",
    "                writer.write(tfrecord.SerializeToString())\n",
    "\n",
    "        print(f\"{count} {len(tfrecords)} {path}\")\n",
    "        count += 1\n",
    "        print(f\"{count}/{total} batchs / {count * batch_size} processed\")\n",
    "\n",
    "    print(f\"{count}/{total} batchs / {len(df)} processed\")\n",
    "    \n",
    "    return tf_path\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5bc708b4-0cdd-46b6-94b6-66998aaa2c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/disks/data/fma/trains/hierarchical_all/tfrecords'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrecord_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0149ac30-6fd3-44f6-8a98-e69dd2740419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1114 /mnt/disks/data/fma/trains/hierarchical_all/tfrecords/val/0000000000.tfrecord\n",
      "1/1 batchs / 51200 processed\n",
      "1/1 batchs / 1114 processed\n"
     ]
    }
   ],
   "source": [
    "val_path = generate_tf_record(df_val,tf_path=os.path.join(tfrecord_path,'val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "770b69f6-8059-4fd7-a514-203302e1bd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1125 /mnt/disks/data/fma/trains/hierarchical_all/tfrecords/test/0000000000.tfrecord\n",
      "1/1 batchs / 51200 processed\n",
      "1/1 batchs / 1125 processed\n"
     ]
    }
   ],
   "source": [
    "test_path = generate_tf_record(df_test,tf_path=os.path.join(tfrecord_path,'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e9ef95bd-ead5-43ac-83e4-16cc24222a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 51200 /mnt/disks/data/fma/trains/hierarchical_all/tfrecords/train/0000000000.tfrecord\n",
      "1/2 batchs / 51200 processed\n",
      "1 51031 /mnt/disks/data/fma/trains/hierarchical_all/tfrecords/train/0000000001.tfrecord\n",
      "2/2 batchs / 102400 processed\n",
      "2/2 batchs / 102231 processed\n"
     ]
    }
   ],
   "source": [
    "train_path = generate_tf_record(df_train,tf_path=os.path.join(tfrecord_path,'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd97175f-4b2b-49e0-bb74-84d12a2999a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata(metadata_path):\n",
    "\n",
    "    with open(metadata_path, 'w+') as f:\n",
    "        f.write(json.dumps({\n",
    "            'sequence_size': args.sequence_size,\n",
    "            'n_levels': labels_size,\n",
    "            'labels_size': [labels['label1_count'],labels['label2_count'],\n",
    "                           labels['label3_count'],labels['label4_count'],\n",
    "                           labels['label5_count']],\n",
    "            'val_path': val_path,\n",
    "            'train_path': train_path,\n",
    "            'test_path': test_path,\n",
    "            'trainset_count': len(df_train),\n",
    "            'validationset_count': len(df_val),\n",
    "            'testset_count': len(df_test)\n",
    "        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39a433f0-af90-4c10-afee-138b9f5c43a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_metadata(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "555117a3-5616-4cc8-9673-6413113f4d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/disks/data/fma/trains/hierarchical_all'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af5df190-01df-4f13-a475-35132a6712f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks.to_csv(os.path.join(job_path,\"tracks.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "339b8ce0-792b-4c94-b70e-3c031aa7b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(categories_labels_path, 'r') as f:\n",
    "    labels = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "32421389-d7bb-42aa-99ae-85b777698fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels_size = {'level1_size': labels['label1_count']-1,\n",
    "        'level2_size': labels['label2_count']-1,\n",
    "        'level3_size': labels['label3_count']-1,\n",
    "        'level4_size': labels['label4_count']-1,\n",
    "        'level5_size': labels['label5_count']-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b50d015a-86cd-40c1-86bf-f034d262d54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels_size['level1_size']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
